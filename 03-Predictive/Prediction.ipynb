{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data   = pd.read_csv('Sliders First Five.csv')\n",
    "future = pd.read_csv('Slider Six - Predict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8299 entries, 0 to 8298\n",
      "Data columns (total 29 columns):\n",
      "Slider #       8299 non-null int64\n",
      "Season         8299 non-null int64\n",
      "CustomerID     8299 non-null int64\n",
      "T_Frequency    8299 non-null int64\n",
      "T_Recency      8299 non-null int64\n",
      "T_First Day    8299 non-null object\n",
      "T_Last Day     8299 non-null object\n",
      "T_Revenue      8299 non-null float64\n",
      "T_Cost         8299 non-null float64\n",
      "T_Profit       8299 non-null float64\n",
      "T_Duration     8299 non-null int64\n",
      "T_IPT          8299 non-null float64\n",
      "T_GM%          8299 non-null float64\n",
      "Frequency      8299 non-null int64\n",
      "Recency        8299 non-null int64\n",
      "First Day      8299 non-null object\n",
      "Last Day       8299 non-null object\n",
      "Revenue        8299 non-null float64\n",
      "Cost           8299 non-null float64\n",
      "Profit         8299 non-null float64\n",
      "Unit Sales     8299 non-null float64\n",
      "Duration       8299 non-null int64\n",
      "IPT            8299 non-null float64\n",
      "GM%            8299 non-null float64\n",
      "Central        8299 non-null int64\n",
      "North          8299 non-null int64\n",
      "South          8299 non-null int64\n",
      "West           8299 non-null int64\n",
      "Score          8299 non-null float64\n",
      "dtypes: float64(12), int64(13), object(4)\n",
      "memory usage: 1.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Slider #</th>\n",
       "      <th>Season</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>T_Frequency</th>\n",
       "      <th>T_Recency</th>\n",
       "      <th>T_First Day</th>\n",
       "      <th>T_Last Day</th>\n",
       "      <th>T_Revenue</th>\n",
       "      <th>T_Cost</th>\n",
       "      <th>T_Profit</th>\n",
       "      <th>...</th>\n",
       "      <th>Profit</th>\n",
       "      <th>Unit Sales</th>\n",
       "      <th>Duration</th>\n",
       "      <th>IPT</th>\n",
       "      <th>GM%</th>\n",
       "      <th>Central</th>\n",
       "      <th>North</th>\n",
       "      <th>South</th>\n",
       "      <th>West</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12347</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>12/7/2017</td>\n",
       "      <td>12/7/2017</td>\n",
       "      <td>218.054862</td>\n",
       "      <td>221.407357</td>\n",
       "      <td>-3.352495</td>\n",
       "      <td>...</td>\n",
       "      <td>257.840047</td>\n",
       "      <td>4866.57250</td>\n",
       "      <td>188</td>\n",
       "      <td>62.666667</td>\n",
       "      <td>0.049936</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12352</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>11/3/2017</td>\n",
       "      <td>11/3/2017</td>\n",
       "      <td>247.394929</td>\n",
       "      <td>237.833029</td>\n",
       "      <td>9.561900</td>\n",
       "      <td>...</td>\n",
       "      <td>271.712700</td>\n",
       "      <td>601.42750</td>\n",
       "      <td>224</td>\n",
       "      <td>37.333333</td>\n",
       "      <td>0.266238</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12358</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>12/8/2017</td>\n",
       "      <td>12/8/2017</td>\n",
       "      <td>162.601854</td>\n",
       "      <td>173.927709</td>\n",
       "      <td>-11.325855</td>\n",
       "      <td>...</td>\n",
       "      <td>23.313165</td>\n",
       "      <td>80.30000</td>\n",
       "      <td>0</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>0.230425</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12359</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>10/13/2017</td>\n",
       "      <td>12/2/2017</td>\n",
       "      <td>17321.015880</td>\n",
       "      <td>9058.471098</td>\n",
       "      <td>8262.544785</td>\n",
       "      <td>...</td>\n",
       "      <td>23859.597940</td>\n",
       "      <td>1882.85325</td>\n",
       "      <td>26</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.587721</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12360</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>10/18/2017</td>\n",
       "      <td>10/18/2017</td>\n",
       "      <td>1049.099664</td>\n",
       "      <td>973.805382</td>\n",
       "      <td>75.294281</td>\n",
       "      <td>...</td>\n",
       "      <td>207.911754</td>\n",
       "      <td>1451.86750</td>\n",
       "      <td>88</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>0.104777</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Slider #  Season  CustomerID  T_Frequency  T_Recency T_First Day  \\\n",
       "0         1       4       12347            1         24   12/7/2017   \n",
       "1         1       4       12352            1         58   11/3/2017   \n",
       "2         1       4       12358            1         23   12/8/2017   \n",
       "3         1       4       12359            2         29  10/13/2017   \n",
       "4         1       4       12360            1         74  10/18/2017   \n",
       "\n",
       "   T_Last Day     T_Revenue       T_Cost     T_Profit  ...          Profit  \\\n",
       "0   12/7/2017    218.054862   221.407357    -3.352495  ...      257.840047   \n",
       "1   11/3/2017    247.394929   237.833029     9.561900  ...      271.712700   \n",
       "2   12/8/2017    162.601854   173.927709   -11.325855  ...       23.313165   \n",
       "3   12/2/2017  17321.015880  9058.471098  8262.544785  ...    23859.597940   \n",
       "4  10/18/2017   1049.099664   973.805382    75.294281  ...      207.911754   \n",
       "\n",
       "   Unit Sales  Duration         IPT       GM% Central North  South  West  \\\n",
       "0  4866.57250       188   62.666667  0.049936       0     1      0     0   \n",
       "1   601.42750       224   37.333333  0.266238       1     0      0     0   \n",
       "2    80.30000         0  279.000000  0.230425       0     0      1     0   \n",
       "3  1882.85325        26   26.000000  0.587721       0     0      0     1   \n",
       "4  1451.86750        88   88.000000  0.104777       0     0      1     0   \n",
       "\n",
       "   Score  \n",
       "0   2.50  \n",
       "1   2.00  \n",
       "2   2.25  \n",
       "3   4.50  \n",
       "4   2.50  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Slider #</th>\n",
       "      <th>Season</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>T_Frequency</th>\n",
       "      <th>T_Recency</th>\n",
       "      <th>T_Revenue</th>\n",
       "      <th>T_Cost</th>\n",
       "      <th>T_Profit</th>\n",
       "      <th>T_Duration</th>\n",
       "      <th>T_IPT</th>\n",
       "      <th>...</th>\n",
       "      <th>Profit</th>\n",
       "      <th>Unit Sales</th>\n",
       "      <th>Duration</th>\n",
       "      <th>IPT</th>\n",
       "      <th>GM%</th>\n",
       "      <th>Central</th>\n",
       "      <th>North</th>\n",
       "      <th>South</th>\n",
       "      <th>West</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8299.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8299.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.138450</td>\n",
       "      <td>2.918785</td>\n",
       "      <td>15283.928425</td>\n",
       "      <td>14.665140</td>\n",
       "      <td>23.872997</td>\n",
       "      <td>2821.062912</td>\n",
       "      <td>2382.108757</td>\n",
       "      <td>438.954156</td>\n",
       "      <td>47.328112</td>\n",
       "      <td>23.240169</td>\n",
       "      <td>...</td>\n",
       "      <td>828.100665</td>\n",
       "      <td>4856.112482</td>\n",
       "      <td>144.293288</td>\n",
       "      <td>57.728345</td>\n",
       "      <td>0.100415</td>\n",
       "      <td>0.396674</td>\n",
       "      <td>0.337511</td>\n",
       "      <td>0.095915</td>\n",
       "      <td>0.169900</td>\n",
       "      <td>3.015198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.386413</td>\n",
       "      <td>1.047398</td>\n",
       "      <td>1725.798927</td>\n",
       "      <td>29.343209</td>\n",
       "      <td>25.219017</td>\n",
       "      <td>11145.608289</td>\n",
       "      <td>8284.732175</td>\n",
       "      <td>5605.007157</td>\n",
       "      <td>32.609893</td>\n",
       "      <td>32.359297</td>\n",
       "      <td>...</td>\n",
       "      <td>4322.781449</td>\n",
       "      <td>14736.061606</td>\n",
       "      <td>90.207797</td>\n",
       "      <td>87.670864</td>\n",
       "      <td>0.141650</td>\n",
       "      <td>0.489237</td>\n",
       "      <td>0.472889</td>\n",
       "      <td>0.294493</td>\n",
       "      <td>0.375568</td>\n",
       "      <td>0.953841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12347.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.207875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-13644.398870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-14360.629840</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.467832</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>13815.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>220.116163</td>\n",
       "      <td>195.308822</td>\n",
       "      <td>1.298308</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.649218</td>\n",
       "      <td>420.725035</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>0.023286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>15236.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>699.323156</td>\n",
       "      <td>620.193886</td>\n",
       "      <td>39.775340</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>92.204731</td>\n",
       "      <td>1244.844700</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.086136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>16802.500000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1862.323031</td>\n",
       "      <td>1678.291173</td>\n",
       "      <td>171.677050</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>368.414158</td>\n",
       "      <td>3422.148300</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>0.168536</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>18287.000000</td>\n",
       "      <td>744.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>457177.414100</td>\n",
       "      <td>282028.616500</td>\n",
       "      <td>452603.780100</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>129859.486300</td>\n",
       "      <td>308335.875000</td>\n",
       "      <td>273.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Slider #       Season    CustomerID  T_Frequency    T_Recency  \\\n",
       "count  8299.000000  8299.000000   8299.000000  8299.000000  8299.000000   \n",
       "mean      3.138450     2.918785  15283.928425    14.665140    23.872997   \n",
       "std       1.386413     1.047398   1725.798927    29.343209    25.219017   \n",
       "min       1.000000     1.000000  12347.000000     1.000000     0.000000   \n",
       "25%       2.000000     2.000000  13815.000000     2.000000     3.000000   \n",
       "50%       3.000000     3.000000  15236.000000     6.000000    15.000000   \n",
       "75%       4.000000     4.000000  16802.500000    15.000000    38.000000   \n",
       "max       5.000000     4.000000  18287.000000   744.000000    91.000000   \n",
       "\n",
       "           T_Revenue         T_Cost       T_Profit   T_Duration        T_IPT  \\\n",
       "count    8299.000000    8299.000000    8299.000000  8299.000000  8299.000000   \n",
       "mean     2821.062912    2382.108757     438.954156    47.328112    23.240169   \n",
       "std     11145.608289    8284.732175    5605.007157    32.609893    32.359297   \n",
       "min         0.207875       0.000000  -13644.398870     0.000000     0.000000   \n",
       "25%       220.116163     195.308822       1.298308    14.000000     4.000000   \n",
       "50%       699.323156     620.193886      39.775340    54.000000     8.000000   \n",
       "75%      1862.323031    1678.291173     171.677050    77.000000    20.000000   \n",
       "max    457177.414100  282028.616500  452603.780100    91.000000    93.000000   \n",
       "\n",
       "          ...              Profit     Unit Sales     Duration          IPT  \\\n",
       "count     ...         8299.000000    8299.000000  8299.000000  8299.000000   \n",
       "mean      ...          828.100665    4856.112482   144.293288    57.728345   \n",
       "std       ...         4322.781449   14736.061606    90.207797    87.670864   \n",
       "min       ...       -14360.629840       0.300000     0.000000     0.000000   \n",
       "25%       ...           11.649218     420.725035    66.000000     7.250000   \n",
       "50%       ...           92.204731    1244.844700   157.000000    19.000000   \n",
       "75%       ...          368.414158    3422.148300   229.000000    53.000000   \n",
       "max       ...       129859.486300  308335.875000   273.000000   279.000000   \n",
       "\n",
       "               GM%      Central        North        South         West  \\\n",
       "count  8299.000000  8299.000000  8299.000000  8299.000000  8299.000000   \n",
       "mean      0.100415     0.396674     0.337511     0.095915     0.169900   \n",
       "std       0.141650     0.489237     0.472889     0.294493     0.375568   \n",
       "min      -3.467832     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.023286     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.086136     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.168536     1.000000     1.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "             Score  \n",
       "count  8299.000000  \n",
       "mean      3.015198  \n",
       "std       0.953841  \n",
       "min       1.000000  \n",
       "25%       2.250000  \n",
       "50%       3.000000  \n",
       "75%       3.750000  \n",
       "max       5.000000  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>T_Profit</th>\n",
       "      <th>T_Revenue</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Recency</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>GM%</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Profit</th>\n",
       "      <th>Duration</th>\n",
       "      <th>IPT</th>\n",
       "      <th>Unit Sales</th>\n",
       "      <th>Central</th>\n",
       "      <th>North</th>\n",
       "      <th>South</th>\n",
       "      <th>West</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8299.000000</td>\n",
       "      <td>8299.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.918785</td>\n",
       "      <td>438.954156</td>\n",
       "      <td>2821.062912</td>\n",
       "      <td>22.685866</td>\n",
       "      <td>39.476804</td>\n",
       "      <td>6058.618211</td>\n",
       "      <td>0.100415</td>\n",
       "      <td>5230.517546</td>\n",
       "      <td>828.100665</td>\n",
       "      <td>144.293288</td>\n",
       "      <td>57.728345</td>\n",
       "      <td>4856.112482</td>\n",
       "      <td>0.396674</td>\n",
       "      <td>0.337511</td>\n",
       "      <td>0.095915</td>\n",
       "      <td>0.169900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.047398</td>\n",
       "      <td>5605.007157</td>\n",
       "      <td>11145.608289</td>\n",
       "      <td>54.101308</td>\n",
       "      <td>59.680000</td>\n",
       "      <td>18411.037770</td>\n",
       "      <td>0.141650</td>\n",
       "      <td>15662.931707</td>\n",
       "      <td>4322.781449</td>\n",
       "      <td>90.207797</td>\n",
       "      <td>87.670864</td>\n",
       "      <td>14736.061606</td>\n",
       "      <td>0.489237</td>\n",
       "      <td>0.472889</td>\n",
       "      <td>0.294493</td>\n",
       "      <td>0.375568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-13644.398870</td>\n",
       "      <td>0.207875</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.776620</td>\n",
       "      <td>-3.467832</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-14360.629840</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.298308</td>\n",
       "      <td>220.116163</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>515.875712</td>\n",
       "      <td>0.023286</td>\n",
       "      <td>460.073582</td>\n",
       "      <td>11.649218</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>420.725035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>39.775340</td>\n",
       "      <td>699.323156</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1522.551450</td>\n",
       "      <td>0.086136</td>\n",
       "      <td>1350.427230</td>\n",
       "      <td>92.204731</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1244.844700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>171.677050</td>\n",
       "      <td>1862.323031</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>4271.846393</td>\n",
       "      <td>0.168536</td>\n",
       "      <td>3878.278987</td>\n",
       "      <td>368.414158</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>3422.148300</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>452603.780100</td>\n",
       "      <td>457177.414100</td>\n",
       "      <td>1508.000000</td>\n",
       "      <td>274.000000</td>\n",
       "      <td>447117.326400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>409230.648900</td>\n",
       "      <td>129859.486300</td>\n",
       "      <td>273.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>308335.875000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Season       T_Profit      T_Revenue    Frequency      Recency  \\\n",
       "count  8299.000000    8299.000000    8299.000000  8299.000000  8299.000000   \n",
       "mean      2.918785     438.954156    2821.062912    22.685866    39.476804   \n",
       "std       1.047398    5605.007157   11145.608289    54.101308    59.680000   \n",
       "min       1.000000  -13644.398870       0.207875     1.000000     0.000000   \n",
       "25%       2.000000       1.298308     220.116163     3.000000     2.000000   \n",
       "50%       3.000000      39.775340     699.323156     8.000000    10.000000   \n",
       "75%       4.000000     171.677050    1862.323031    21.000000    47.000000   \n",
       "max       4.000000  452603.780100  457177.414100  1508.000000   274.000000   \n",
       "\n",
       "             Revenue          GM%           Cost         Profit     Duration  \\\n",
       "count    8299.000000  8299.000000    8299.000000    8299.000000  8299.000000   \n",
       "mean     6058.618211     0.100415    5230.517546     828.100665   144.293288   \n",
       "std     18411.037770     0.141650   15662.931707    4322.781449    90.207797   \n",
       "min         0.776620    -3.467832       0.000000  -14360.629840     0.000000   \n",
       "25%       515.875712     0.023286     460.073582      11.649218    66.000000   \n",
       "50%      1522.551450     0.086136    1350.427230      92.204731   157.000000   \n",
       "75%      4271.846393     0.168536    3878.278987     368.414158   229.000000   \n",
       "max    447117.326400     1.000000  409230.648900  129859.486300   273.000000   \n",
       "\n",
       "               IPT     Unit Sales      Central        North        South  \\\n",
       "count  8299.000000    8299.000000  8299.000000  8299.000000  8299.000000   \n",
       "mean     57.728345    4856.112482     0.396674     0.337511     0.095915   \n",
       "std      87.670864   14736.061606     0.489237     0.472889     0.294493   \n",
       "min       0.000000       0.300000     0.000000     0.000000     0.000000   \n",
       "25%       7.250000     420.725035     0.000000     0.000000     0.000000   \n",
       "50%      19.000000    1244.844700     0.000000     0.000000     0.000000   \n",
       "75%      53.000000    3422.148300     1.000000     1.000000     0.000000   \n",
       "max     279.000000  308335.875000     1.000000     1.000000     1.000000   \n",
       "\n",
       "              West  \n",
       "count  8299.000000  \n",
       "mean      0.169900  \n",
       "std       0.375568  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       0.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exploration\n",
    "variables = ['Season','T_Profit','T_Revenue','Frequency','Recency','Revenue','GM%','Cost',\n",
    "             'Profit','Duration','IPT','Unit Sales','Central','North','South','West']\n",
    "\n",
    "\n",
    "data[variables].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['T_Profit'].hist(bins = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['T_Revenue'].hist(bins = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['L_Revenue'] = np.log(data['T_Revenue'])\n",
    "\n",
    "data['L_Revenue'].hist(bins = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>T_Profit</th>\n",
       "      <th>T_Revenue</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Recency</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>GM%</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Profit</th>\n",
       "      <th>Duration</th>\n",
       "      <th>IPT</th>\n",
       "      <th>Unit Sales</th>\n",
       "      <th>Central</th>\n",
       "      <th>North</th>\n",
       "      <th>South</th>\n",
       "      <th>West</th>\n",
       "      <th>L_Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Season</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005520</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.169831</td>\n",
       "      <td>-0.218342</td>\n",
       "      <td>0.009727</td>\n",
       "      <td>0.024827</td>\n",
       "      <td>0.005550</td>\n",
       "      <td>0.021318</td>\n",
       "      <td>0.038736</td>\n",
       "      <td>-0.084451</td>\n",
       "      <td>0.009229</td>\n",
       "      <td>0.019134</td>\n",
       "      <td>-0.028836</td>\n",
       "      <td>0.199118</td>\n",
       "      <td>-0.144749</td>\n",
       "      <td>0.027257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T_Profit</th>\n",
       "      <td>0.005520</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.696352</td>\n",
       "      <td>0.094301</td>\n",
       "      <td>-0.018974</td>\n",
       "      <td>0.145795</td>\n",
       "      <td>0.083231</td>\n",
       "      <td>0.084976</td>\n",
       "      <td>0.313053</td>\n",
       "      <td>0.029507</td>\n",
       "      <td>-0.026895</td>\n",
       "      <td>0.091690</td>\n",
       "      <td>-0.044370</td>\n",
       "      <td>0.034096</td>\n",
       "      <td>0.033185</td>\n",
       "      <td>-0.011153</td>\n",
       "      <td>0.163320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T_Revenue</th>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.696352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.275990</td>\n",
       "      <td>-0.070085</td>\n",
       "      <td>0.423169</td>\n",
       "      <td>0.054948</td>\n",
       "      <td>0.414214</td>\n",
       "      <td>0.301466</td>\n",
       "      <td>0.137781</td>\n",
       "      <td>-0.088243</td>\n",
       "      <td>0.381671</td>\n",
       "      <td>-0.108470</td>\n",
       "      <td>0.105928</td>\n",
       "      <td>0.016193</td>\n",
       "      <td>-0.004774</td>\n",
       "      <td>0.428519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frequency</th>\n",
       "      <td>0.169831</td>\n",
       "      <td>0.094301</td>\n",
       "      <td>0.275990</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.223617</td>\n",
       "      <td>0.467594</td>\n",
       "      <td>0.062589</td>\n",
       "      <td>0.467855</td>\n",
       "      <td>0.296318</td>\n",
       "      <td>0.334859</td>\n",
       "      <td>-0.233545</td>\n",
       "      <td>0.488100</td>\n",
       "      <td>-0.157311</td>\n",
       "      <td>0.213509</td>\n",
       "      <td>-0.079095</td>\n",
       "      <td>-0.001892</td>\n",
       "      <td>0.324950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recency</th>\n",
       "      <td>-0.218342</td>\n",
       "      <td>-0.018974</td>\n",
       "      <td>-0.070085</td>\n",
       "      <td>-0.223617</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.116786</td>\n",
       "      <td>-0.008523</td>\n",
       "      <td>-0.118029</td>\n",
       "      <td>-0.069740</td>\n",
       "      <td>-0.542913</td>\n",
       "      <td>0.511776</td>\n",
       "      <td>-0.119268</td>\n",
       "      <td>0.101354</td>\n",
       "      <td>-0.104735</td>\n",
       "      <td>0.021972</td>\n",
       "      <td>-0.017384</td>\n",
       "      <td>-0.239562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Revenue</th>\n",
       "      <td>0.009727</td>\n",
       "      <td>0.145795</td>\n",
       "      <td>0.423169</td>\n",
       "      <td>0.467594</td>\n",
       "      <td>-0.116786</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.084263</td>\n",
       "      <td>0.980694</td>\n",
       "      <td>0.705677</td>\n",
       "      <td>0.253624</td>\n",
       "      <td>-0.150086</td>\n",
       "      <td>0.968392</td>\n",
       "      <td>-0.170537</td>\n",
       "      <td>0.180540</td>\n",
       "      <td>-0.021185</td>\n",
       "      <td>0.011440</td>\n",
       "      <td>0.312367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM%</th>\n",
       "      <td>0.024827</td>\n",
       "      <td>0.083231</td>\n",
       "      <td>0.054948</td>\n",
       "      <td>0.062589</td>\n",
       "      <td>-0.008523</td>\n",
       "      <td>0.084263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027335</td>\n",
       "      <td>0.259838</td>\n",
       "      <td>0.031322</td>\n",
       "      <td>-0.040759</td>\n",
       "      <td>0.057314</td>\n",
       "      <td>-0.025338</td>\n",
       "      <td>0.025797</td>\n",
       "      <td>-0.013339</td>\n",
       "      <td>0.010983</td>\n",
       "      <td>0.025257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cost</th>\n",
       "      <td>0.005550</td>\n",
       "      <td>0.084976</td>\n",
       "      <td>0.414214</td>\n",
       "      <td>0.467855</td>\n",
       "      <td>-0.118029</td>\n",
       "      <td>0.980694</td>\n",
       "      <td>0.027335</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.553502</td>\n",
       "      <td>0.259143</td>\n",
       "      <td>-0.150564</td>\n",
       "      <td>0.955758</td>\n",
       "      <td>-0.169300</td>\n",
       "      <td>0.179684</td>\n",
       "      <td>-0.028338</td>\n",
       "      <td>0.016515</td>\n",
       "      <td>0.316273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profit</th>\n",
       "      <td>0.021318</td>\n",
       "      <td>0.313053</td>\n",
       "      <td>0.301466</td>\n",
       "      <td>0.296318</td>\n",
       "      <td>-0.069740</td>\n",
       "      <td>0.705677</td>\n",
       "      <td>0.259838</td>\n",
       "      <td>0.553502</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.141240</td>\n",
       "      <td>-0.093681</td>\n",
       "      <td>0.661408</td>\n",
       "      <td>-0.112899</td>\n",
       "      <td>0.117879</td>\n",
       "      <td>0.012449</td>\n",
       "      <td>-0.011118</td>\n",
       "      <td>0.184428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Duration</th>\n",
       "      <td>0.038736</td>\n",
       "      <td>0.029507</td>\n",
       "      <td>0.137781</td>\n",
       "      <td>0.334859</td>\n",
       "      <td>-0.542913</td>\n",
       "      <td>0.253624</td>\n",
       "      <td>0.031322</td>\n",
       "      <td>0.259143</td>\n",
       "      <td>0.141240</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.536811</td>\n",
       "      <td>0.252868</td>\n",
       "      <td>-0.208360</td>\n",
       "      <td>0.325962</td>\n",
       "      <td>-0.298323</td>\n",
       "      <td>0.094915</td>\n",
       "      <td>0.329585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IPT</th>\n",
       "      <td>-0.084451</td>\n",
       "      <td>-0.026895</td>\n",
       "      <td>-0.088243</td>\n",
       "      <td>-0.233545</td>\n",
       "      <td>0.511776</td>\n",
       "      <td>-0.150086</td>\n",
       "      <td>-0.040759</td>\n",
       "      <td>-0.150564</td>\n",
       "      <td>-0.093681</td>\n",
       "      <td>-0.536811</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.150407</td>\n",
       "      <td>0.057264</td>\n",
       "      <td>-0.175930</td>\n",
       "      <td>0.244671</td>\n",
       "      <td>-0.044930</td>\n",
       "      <td>-0.237693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unit Sales</th>\n",
       "      <td>0.009229</td>\n",
       "      <td>0.091690</td>\n",
       "      <td>0.381671</td>\n",
       "      <td>0.488100</td>\n",
       "      <td>-0.119268</td>\n",
       "      <td>0.968392</td>\n",
       "      <td>0.057314</td>\n",
       "      <td>0.955758</td>\n",
       "      <td>0.661408</td>\n",
       "      <td>0.252868</td>\n",
       "      <td>-0.150407</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.171186</td>\n",
       "      <td>0.185046</td>\n",
       "      <td>-0.027452</td>\n",
       "      <td>0.011525</td>\n",
       "      <td>0.306977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Central</th>\n",
       "      <td>0.019134</td>\n",
       "      <td>-0.044370</td>\n",
       "      <td>-0.108470</td>\n",
       "      <td>-0.157311</td>\n",
       "      <td>0.101354</td>\n",
       "      <td>-0.170537</td>\n",
       "      <td>-0.025338</td>\n",
       "      <td>-0.169300</td>\n",
       "      <td>-0.112899</td>\n",
       "      <td>-0.208360</td>\n",
       "      <td>0.057264</td>\n",
       "      <td>-0.171186</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.578756</td>\n",
       "      <td>-0.264107</td>\n",
       "      <td>-0.366837</td>\n",
       "      <td>-0.171431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North</th>\n",
       "      <td>-0.028836</td>\n",
       "      <td>0.034096</td>\n",
       "      <td>0.105928</td>\n",
       "      <td>0.213509</td>\n",
       "      <td>-0.104735</td>\n",
       "      <td>0.180540</td>\n",
       "      <td>0.025797</td>\n",
       "      <td>0.179684</td>\n",
       "      <td>0.117879</td>\n",
       "      <td>0.325962</td>\n",
       "      <td>-0.175930</td>\n",
       "      <td>0.185046</td>\n",
       "      <td>-0.578756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.232484</td>\n",
       "      <td>-0.322913</td>\n",
       "      <td>0.219731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South</th>\n",
       "      <td>0.199118</td>\n",
       "      <td>0.033185</td>\n",
       "      <td>0.016193</td>\n",
       "      <td>-0.079095</td>\n",
       "      <td>0.021972</td>\n",
       "      <td>-0.021185</td>\n",
       "      <td>-0.013339</td>\n",
       "      <td>-0.028338</td>\n",
       "      <td>0.012449</td>\n",
       "      <td>-0.298323</td>\n",
       "      <td>0.244671</td>\n",
       "      <td>-0.027452</td>\n",
       "      <td>-0.264107</td>\n",
       "      <td>-0.232484</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.147357</td>\n",
       "      <td>-0.048493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West</th>\n",
       "      <td>-0.144749</td>\n",
       "      <td>-0.011153</td>\n",
       "      <td>-0.004774</td>\n",
       "      <td>-0.001892</td>\n",
       "      <td>-0.017384</td>\n",
       "      <td>0.011440</td>\n",
       "      <td>0.010983</td>\n",
       "      <td>0.016515</td>\n",
       "      <td>-0.011118</td>\n",
       "      <td>0.094915</td>\n",
       "      <td>-0.044930</td>\n",
       "      <td>0.011525</td>\n",
       "      <td>-0.366837</td>\n",
       "      <td>-0.322913</td>\n",
       "      <td>-0.147357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.015330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L_Revenue</th>\n",
       "      <td>0.027257</td>\n",
       "      <td>0.163320</td>\n",
       "      <td>0.428519</td>\n",
       "      <td>0.324950</td>\n",
       "      <td>-0.239562</td>\n",
       "      <td>0.312367</td>\n",
       "      <td>0.025257</td>\n",
       "      <td>0.316273</td>\n",
       "      <td>0.184428</td>\n",
       "      <td>0.329585</td>\n",
       "      <td>-0.237693</td>\n",
       "      <td>0.306977</td>\n",
       "      <td>-0.171431</td>\n",
       "      <td>0.219731</td>\n",
       "      <td>-0.048493</td>\n",
       "      <td>-0.015330</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Season  T_Profit  T_Revenue  Frequency   Recency   Revenue  \\\n",
       "Season      1.000000  0.005520   0.000201   0.169831 -0.218342  0.009727   \n",
       "T_Profit    0.005520  1.000000   0.696352   0.094301 -0.018974  0.145795   \n",
       "T_Revenue   0.000201  0.696352   1.000000   0.275990 -0.070085  0.423169   \n",
       "Frequency   0.169831  0.094301   0.275990   1.000000 -0.223617  0.467594   \n",
       "Recency    -0.218342 -0.018974  -0.070085  -0.223617  1.000000 -0.116786   \n",
       "Revenue     0.009727  0.145795   0.423169   0.467594 -0.116786  1.000000   \n",
       "GM%         0.024827  0.083231   0.054948   0.062589 -0.008523  0.084263   \n",
       "Cost        0.005550  0.084976   0.414214   0.467855 -0.118029  0.980694   \n",
       "Profit      0.021318  0.313053   0.301466   0.296318 -0.069740  0.705677   \n",
       "Duration    0.038736  0.029507   0.137781   0.334859 -0.542913  0.253624   \n",
       "IPT        -0.084451 -0.026895  -0.088243  -0.233545  0.511776 -0.150086   \n",
       "Unit Sales  0.009229  0.091690   0.381671   0.488100 -0.119268  0.968392   \n",
       "Central     0.019134 -0.044370  -0.108470  -0.157311  0.101354 -0.170537   \n",
       "North      -0.028836  0.034096   0.105928   0.213509 -0.104735  0.180540   \n",
       "South       0.199118  0.033185   0.016193  -0.079095  0.021972 -0.021185   \n",
       "West       -0.144749 -0.011153  -0.004774  -0.001892 -0.017384  0.011440   \n",
       "L_Revenue   0.027257  0.163320   0.428519   0.324950 -0.239562  0.312367   \n",
       "\n",
       "                 GM%      Cost    Profit  Duration       IPT  Unit Sales  \\\n",
       "Season      0.024827  0.005550  0.021318  0.038736 -0.084451    0.009229   \n",
       "T_Profit    0.083231  0.084976  0.313053  0.029507 -0.026895    0.091690   \n",
       "T_Revenue   0.054948  0.414214  0.301466  0.137781 -0.088243    0.381671   \n",
       "Frequency   0.062589  0.467855  0.296318  0.334859 -0.233545    0.488100   \n",
       "Recency    -0.008523 -0.118029 -0.069740 -0.542913  0.511776   -0.119268   \n",
       "Revenue     0.084263  0.980694  0.705677  0.253624 -0.150086    0.968392   \n",
       "GM%         1.000000  0.027335  0.259838  0.031322 -0.040759    0.057314   \n",
       "Cost        0.027335  1.000000  0.553502  0.259143 -0.150564    0.955758   \n",
       "Profit      0.259838  0.553502  1.000000  0.141240 -0.093681    0.661408   \n",
       "Duration    0.031322  0.259143  0.141240  1.000000 -0.536811    0.252868   \n",
       "IPT        -0.040759 -0.150564 -0.093681 -0.536811  1.000000   -0.150407   \n",
       "Unit Sales  0.057314  0.955758  0.661408  0.252868 -0.150407    1.000000   \n",
       "Central    -0.025338 -0.169300 -0.112899 -0.208360  0.057264   -0.171186   \n",
       "North       0.025797  0.179684  0.117879  0.325962 -0.175930    0.185046   \n",
       "South      -0.013339 -0.028338  0.012449 -0.298323  0.244671   -0.027452   \n",
       "West        0.010983  0.016515 -0.011118  0.094915 -0.044930    0.011525   \n",
       "L_Revenue   0.025257  0.316273  0.184428  0.329585 -0.237693    0.306977   \n",
       "\n",
       "             Central     North     South      West  L_Revenue  \n",
       "Season      0.019134 -0.028836  0.199118 -0.144749   0.027257  \n",
       "T_Profit   -0.044370  0.034096  0.033185 -0.011153   0.163320  \n",
       "T_Revenue  -0.108470  0.105928  0.016193 -0.004774   0.428519  \n",
       "Frequency  -0.157311  0.213509 -0.079095 -0.001892   0.324950  \n",
       "Recency     0.101354 -0.104735  0.021972 -0.017384  -0.239562  \n",
       "Revenue    -0.170537  0.180540 -0.021185  0.011440   0.312367  \n",
       "GM%        -0.025338  0.025797 -0.013339  0.010983   0.025257  \n",
       "Cost       -0.169300  0.179684 -0.028338  0.016515   0.316273  \n",
       "Profit     -0.112899  0.117879  0.012449 -0.011118   0.184428  \n",
       "Duration   -0.208360  0.325962 -0.298323  0.094915   0.329585  \n",
       "IPT         0.057264 -0.175930  0.244671 -0.044930  -0.237693  \n",
       "Unit Sales -0.171186  0.185046 -0.027452  0.011525   0.306977  \n",
       "Central     1.000000 -0.578756 -0.264107 -0.366837  -0.171431  \n",
       "North      -0.578756  1.000000 -0.232484 -0.322913   0.219731  \n",
       "South      -0.264107 -0.232484  1.000000 -0.147357  -0.048493  \n",
       "West       -0.366837 -0.322913 -0.147357  1.000000  -0.015330  \n",
       "L_Revenue  -0.171431  0.219731 -0.048493 -0.015330   1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables.append('L_Revenue')\n",
    "\n",
    "data[variables].corr()\n",
    "\n",
    "# no variable highly correlated to profit, revenue, or log revenue, so no data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8299 entries, 0 to 8298\n",
      "Data columns (total 4 columns):\n",
      "1    8299 non-null uint8\n",
      "2    8299 non-null uint8\n",
      "3    8299 non-null uint8\n",
      "4    8299 non-null uint8\n",
      "dtypes: uint8(4)\n",
      "memory usage: 32.5 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1  2  3  4\n",
       "0  0  0  0  1\n",
       "1  0  0  0  1\n",
       "2  0  0  0  1\n",
       "3  0  0  0  1\n",
       "4  0  0  0  1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = pd.get_dummies(data['Season'])\n",
    "\n",
    "dummy.info()\n",
    "dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8299 entries, 0 to 8298\n",
      "Data columns (total 34 columns):\n",
      "Slider #       8299 non-null int64\n",
      "Season         8299 non-null int64\n",
      "CustomerID     8299 non-null int64\n",
      "T_Frequency    8299 non-null int64\n",
      "T_Recency      8299 non-null int64\n",
      "T_First Day    8299 non-null object\n",
      "T_Last Day     8299 non-null object\n",
      "T_Revenue      8299 non-null float64\n",
      "T_Cost         8299 non-null float64\n",
      "T_Profit       8299 non-null float64\n",
      "T_Duration     8299 non-null int64\n",
      "T_IPT          8299 non-null float64\n",
      "T_GM%          8299 non-null float64\n",
      "Frequency      8299 non-null int64\n",
      "Recency        8299 non-null int64\n",
      "First Day      8299 non-null object\n",
      "Last Day       8299 non-null object\n",
      "Revenue        8299 non-null float64\n",
      "Cost           8299 non-null float64\n",
      "Profit         8299 non-null float64\n",
      "Unit Sales     8299 non-null float64\n",
      "Duration       8299 non-null int64\n",
      "IPT            8299 non-null float64\n",
      "GM%            8299 non-null float64\n",
      "Central        8299 non-null int64\n",
      "North          8299 non-null int64\n",
      "South          8299 non-null int64\n",
      "West           8299 non-null int64\n",
      "Score          8299 non-null float64\n",
      "L_Revenue      8299 non-null float64\n",
      "Season 1       8299 non-null uint8\n",
      "Season 2       8299 non-null uint8\n",
      "Season 3       8299 non-null uint8\n",
      "Season 4       8299 non-null uint8\n",
      "dtypes: float64(13), int64(13), object(4), uint8(4)\n",
      "memory usage: 1.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Slider #</th>\n",
       "      <th>Season</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>T_Frequency</th>\n",
       "      <th>T_Recency</th>\n",
       "      <th>T_First Day</th>\n",
       "      <th>T_Last Day</th>\n",
       "      <th>T_Revenue</th>\n",
       "      <th>T_Cost</th>\n",
       "      <th>T_Profit</th>\n",
       "      <th>...</th>\n",
       "      <th>Central</th>\n",
       "      <th>North</th>\n",
       "      <th>South</th>\n",
       "      <th>West</th>\n",
       "      <th>Score</th>\n",
       "      <th>L_Revenue</th>\n",
       "      <th>Season 1</th>\n",
       "      <th>Season 2</th>\n",
       "      <th>Season 3</th>\n",
       "      <th>Season 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12347</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>12/7/2017</td>\n",
       "      <td>12/7/2017</td>\n",
       "      <td>218.054862</td>\n",
       "      <td>221.407357</td>\n",
       "      <td>-3.352495</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>5.384747</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12352</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>11/3/2017</td>\n",
       "      <td>11/3/2017</td>\n",
       "      <td>247.394929</td>\n",
       "      <td>237.833029</td>\n",
       "      <td>9.561900</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5.510986</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12358</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>12/8/2017</td>\n",
       "      <td>12/8/2017</td>\n",
       "      <td>162.601854</td>\n",
       "      <td>173.927709</td>\n",
       "      <td>-11.325855</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>5.091305</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12359</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>10/13/2017</td>\n",
       "      <td>12/2/2017</td>\n",
       "      <td>17321.015880</td>\n",
       "      <td>9058.471098</td>\n",
       "      <td>8262.544785</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.50</td>\n",
       "      <td>9.759676</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12360</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>10/18/2017</td>\n",
       "      <td>10/18/2017</td>\n",
       "      <td>1049.099664</td>\n",
       "      <td>973.805382</td>\n",
       "      <td>75.294281</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>6.955688</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Slider #  Season  CustomerID  T_Frequency  T_Recency T_First Day  \\\n",
       "0         1       4       12347            1         24   12/7/2017   \n",
       "1         1       4       12352            1         58   11/3/2017   \n",
       "2         1       4       12358            1         23   12/8/2017   \n",
       "3         1       4       12359            2         29  10/13/2017   \n",
       "4         1       4       12360            1         74  10/18/2017   \n",
       "\n",
       "   T_Last Day     T_Revenue       T_Cost     T_Profit    ...     Central  \\\n",
       "0   12/7/2017    218.054862   221.407357    -3.352495    ...           0   \n",
       "1   11/3/2017    247.394929   237.833029     9.561900    ...           1   \n",
       "2   12/8/2017    162.601854   173.927709   -11.325855    ...           0   \n",
       "3   12/2/2017  17321.015880  9058.471098  8262.544785    ...           0   \n",
       "4  10/18/2017   1049.099664   973.805382    75.294281    ...           0   \n",
       "\n",
       "   North  South  West  Score L_Revenue Season 1  Season 2  Season 3  Season 4  \n",
       "0      1      0     0   2.50  5.384747        0         0         0         1  \n",
       "1      0      0     0   2.00  5.510986        0         0         0         1  \n",
       "2      0      1     0   2.25  5.091305        0         0         0         1  \n",
       "3      0      0     1   4.50  9.759676        0         0         0         1  \n",
       "4      0      1     0   2.50  6.955688        0         0         0         1  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy.rename(columns={1: 'Season 1',\n",
    "                      2: 'Season 2',\n",
    "                      3: 'Season 3',\n",
    "                      4: 'Season 4'}, inplace=True)\n",
    "\n",
    "d = pd.concat([data,dummy], axis = 1)\n",
    "\n",
    "d.info()\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan A: Try use slider # 5 as testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6692, 15) (1607, 15) (6692,) (1607,)\n"
     ]
    }
   ],
   "source": [
    "# training: tr, testing: te\n",
    "tr = d[d['Slider #']!=5]\n",
    "te = d[d['Slider #']==5]\n",
    "\n",
    "# central and season 4 are excluded from features to avoid perfect collinearity\n",
    "X_label = ['Frequency','Recency','Revenue','GM%','Cost','Profit','Duration','IPT','Unit Sales',\n",
    "           'North','South','West','Season 1','Season 2','Season 3']\n",
    "\n",
    "x_tr = tr[X_label]\n",
    "x_te = te[X_label]\n",
    "\n",
    "y_tr1 = tr['T_Profit']\n",
    "y_te1 = te['T_Profit']\n",
    "y_tr2 = tr['T_Revenue']\n",
    "y_te2 = te['T_Revenue']\n",
    "y_tr3 = tr['L_Revenue']\n",
    "y_te3 = te['L_Revenue']\n",
    "\n",
    "print(x_tr.shape,x_te.shape,y_tr1.shape,y_te1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\STU\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "x_tr = scaler.fit_transform(x_tr)\n",
    "x_te = scaler.transform(x_te)\n",
    "\n",
    "x_tr1 = x_tr\n",
    "x_tr2 = x_tr\n",
    "x_tr3 = x_tr\n",
    "x_te1 = x_te\n",
    "x_te2 = x_te\n",
    "x_te3 = x_te"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan A: Try use slider # 5 as testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan B: Try randomly split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8299, 15) (8299,) (8299,) (8299,)\n"
     ]
    }
   ],
   "source": [
    "X_label = ['Frequency','Recency','Revenue','GM%','Cost','Profit','Duration','IPT','Unit Sales',\n",
    "           'North','South','West','Season 1','Season 2','Season 3']\n",
    "\n",
    "X  = d[X_label]\n",
    "Y1 = data['T_Profit']\n",
    "Y2 = data['T_Revenue']\n",
    "Y3 = data['L_Revenue']\n",
    "\n",
    "print(X.shape,Y1.shape,Y2.shape,Y3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6224, 15) (6224, 15) (6224, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\STU\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\STU\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\STU\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "x_tr1,x_te1,y_tr1,y_te1 = train_test_split(X,Y1,random_state=10)\n",
    "x_tr2,x_te2,y_tr2,y_te2 = train_test_split(X,Y2,random_state=10)\n",
    "x_tr3,x_te3,y_tr3,y_te3 = train_test_split(X,Y3,random_state=10)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "x_tr1 = scaler.fit_transform(x_tr1)\n",
    "x_tr2 = scaler.fit_transform(x_tr2)\n",
    "x_tr3 = scaler.fit_transform(x_tr3)\n",
    "\n",
    "x_te1 = scaler.transform(x_te1)\n",
    "x_te2 = scaler.transform(x_te2)\n",
    "x_te3 = scaler.transform(x_te3)\n",
    "\n",
    "print(x_tr1.shape,x_tr2.shape,x_tr3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan B: Try randomly split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try basic regressors first\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge,LassoCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "\n",
    "XY_list    = [(x_tr1,y_tr1),(x_tr2,y_tr2),(x_tr3,y_tr3)]\n",
    "Y_list_idx = ['Y1','Y2','Y3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\STU\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\STU\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\STU\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Y1</th>\n",
       "      <td>0.015120</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y2</th>\n",
       "      <td>0.109868</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y3</th>\n",
       "      <td>0.173981</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      scores  params\n",
       "Y1  0.015120      98\n",
       "Y2  0.109868      13\n",
       "Y3  0.173981      31"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# knn grid\n",
    "grid_scores = []\n",
    "grid_params = []\n",
    "\n",
    "param_grid = {'n_neighbors': range(1,100)}\n",
    "\n",
    "for (x,y) in XY_list:\n",
    "    grid = GridSearchCV(KNeighborsRegressor(), param_grid)\n",
    "    grid.fit(x,y)\n",
    "    grid_scores.append(grid.best_score_)\n",
    "    grid_params.append(grid.best_params_)\n",
    "\n",
    "grid_scores = pd.DataFrame(grid_scores)\n",
    "grid_params = pd.DataFrame(grid_params)\n",
    "grid_scores = grid_scores.set_index([Y_list_idx])\n",
    "grid_params = grid_params.set_index([Y_list_idx])\n",
    "grid_scores.columns = ['scores']\n",
    "grid_params.columns = ['params']\n",
    "\n",
    "kreg_grid = pd.concat([grid_scores,grid_params], axis = 1)\n",
    "kreg_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Y1</th>\n",
       "      <td>0.054258</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y2</th>\n",
       "      <td>0.235777</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y3</th>\n",
       "      <td>0.194054</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      scores  params\n",
       "Y1  0.054258    1.00\n",
       "Y2  0.235777    0.01\n",
       "Y3  0.194054    1.00"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ridge grid\n",
    "grid_scores = []\n",
    "grid_params = []\n",
    "\n",
    "param_grid = {'alpha': [0.01,0.1,1,10,100]}\n",
    "\n",
    "for (x,y) in XY_list:\n",
    "    grid = GridSearchCV(Ridge(), param_grid, cv = 5)\n",
    "    grid.fit(x,y)\n",
    "    grid_scores.append(grid.best_score_)\n",
    "    grid_params.append(grid.best_params_)\n",
    "\n",
    "grid_scores = pd.DataFrame(grid_scores)\n",
    "grid_params = pd.DataFrame(grid_params)\n",
    "grid_scores = grid_scores.set_index([Y_list_idx])\n",
    "grid_params = grid_params.set_index([Y_list_idx])\n",
    "grid_scores.columns = ['scores']\n",
    "grid_params.columns = ['params']\n",
    "\n",
    "rdge_grid = pd.concat([grid_scores,grid_params], axis = 1)\n",
    "rdge_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\STU\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\STU\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\STU\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "      <th>param1</th>\n",
       "      <th>param2</th>\n",
       "      <th>param3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Y1</th>\n",
       "      <td>-0.003317</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y2</th>\n",
       "      <td>-0.020413</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y3</th>\n",
       "      <td>0.220076</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      scores  param1  param2  param3\n",
       "Y1 -0.003317     100     100     1.0\n",
       "Y2 -0.020413     100       1     0.1\n",
       "Y3  0.220076     100       1     0.1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# svm grid\n",
    "grid_scores = []\n",
    "grid_params = []\n",
    "\n",
    "param_grid = {'C'      : [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'epsilon': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'gamma'  : [0.1, 1, 10]}\n",
    "\n",
    "for (x,y) in XY_list:\n",
    "    grid = GridSearchCV(SVR(kernel = 'rbf'), param_grid)\n",
    "    grid.fit(x,y)\n",
    "    grid_scores.append(grid.best_score_)\n",
    "    grid_params.append(grid.best_params_)\n",
    "\n",
    "grid_scores = pd.DataFrame(grid_scores)\n",
    "grid_params = pd.DataFrame(grid_params)\n",
    "grid_scores = grid_scores.set_index([Y_list_idx])\n",
    "grid_params = grid_params.set_index([Y_list_idx])\n",
    "grid_scores.columns = ['scores']\n",
    "grid_params.columns = ['param1','param2','param3']\n",
    "\n",
    "sreg_grid = pd.concat([grid_scores,grid_params], axis = 1)\n",
    "sreg_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\STU\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "      <th>param1</th>\n",
       "      <th>param2</th>\n",
       "      <th>param3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Y1</th>\n",
       "      <td>0.033043</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y2</th>\n",
       "      <td>0.163147</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y3</th>\n",
       "      <td>0.238403</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>best</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      scores  param1  param2  param3\n",
       "Y1  0.033043       1       5  random\n",
       "Y2  0.163147       2       5    best\n",
       "Y3  0.238403       3      20    best"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tree grid\n",
    "grid_scores = []\n",
    "grid_params = []\n",
    "\n",
    "param_grid = {'max_depth'     : [1,2,3],\n",
    "              'max_leaf_nodes': [5,10,15,20],\n",
    "              'splitter'      : ['best','random']}\n",
    "\n",
    "for (x,y) in XY_list:\n",
    "    grid = GridSearchCV(DecisionTreeRegressor(random_state=0), param_grid, cv = 5)\n",
    "    grid.fit(x,y)\n",
    "    grid_scores.append(grid.best_score_)\n",
    "    grid_params.append(grid.best_params_)\n",
    "\n",
    "grid_scores = pd.DataFrame(grid_scores)\n",
    "grid_params = pd.DataFrame(grid_params)\n",
    "grid_scores = grid_scores.set_index([Y_list_idx])\n",
    "grid_params = grid_params.set_index([Y_list_idx])\n",
    "grid_scores.columns = ['scores']\n",
    "grid_params.columns = ['param1','param2','param3']\n",
    "\n",
    "tree_grid = pd.concat([grid_scores,grid_params], axis = 1)\n",
    "tree_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "      <th>param1</th>\n",
       "      <th>param2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Y1</th>\n",
       "      <td>-0.118824</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y2</th>\n",
       "      <td>0.170997</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y3</th>\n",
       "      <td>0.273792</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      scores  param1  param2\n",
       "Y1 -0.118824      10      12\n",
       "Y2  0.170997      10      15\n",
       "Y3  0.273792      20      13"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forest grid\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "grid_scores = []\n",
    "grid_params = []\n",
    "\n",
    "param_grid = {'max_leaf_nodes': range(10,21),\n",
    "              'n_estimators'  : range(10,21)}\n",
    "\n",
    "for (x,y) in XY_list:\n",
    "    grid = GridSearchCV(RandomForestRegressor(random_state=0), param_grid, cv = 5)\n",
    "    grid.fit(x,y)\n",
    "    grid_scores.append(grid.best_score_)\n",
    "    grid_params.append(grid.best_params_)\n",
    "\n",
    "grid_scores = pd.DataFrame(grid_scores)\n",
    "grid_params = pd.DataFrame(grid_params)\n",
    "grid_scores = grid_scores.set_index([Y_list_idx])\n",
    "grid_params = grid_params.set_index([Y_list_idx])\n",
    "grid_scores.columns = ['scores']\n",
    "grid_params.columns = ['param1','param2']\n",
    "\n",
    "rdft_grid = pd.concat([grid_scores,grid_params], axis = 1)\n",
    "rdft_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary for y1 - profit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "kreg = KNeighborsRegressor(n_neighbors=98)\n",
    "lreg = LinearRegression()\n",
    "rdge = Ridge(alpha=1)\n",
    "lass = LassoCV(cv=5)\n",
    "sreg = SVR(kernel='rbf', C=100,  epsilon=100, gamma=1)\n",
    "tree = DecisionTreeRegressor(splitter='random', max_depth=1, max_leaf_nodes=5, random_state=0)\n",
    "rdft = RandomForestRegressor(n_estimators=12, max_leaf_nodes=10, random_state=0)\n",
    "\n",
    "models    = [kreg,lreg,rdge,lass,sreg,tree,rdft]\n",
    "model_idx = ['kreg','lreg','rdge','lass','sreg','tree','rdft']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profit_R2</th>\n",
       "      <th>profit_MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>kreg</th>\n",
       "      <td>0.001669</td>\n",
       "      <td>1.304500e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lreg</th>\n",
       "      <td>0.038859</td>\n",
       "      <td>1.255904e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rdge</th>\n",
       "      <td>0.029830</td>\n",
       "      <td>1.267703e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lass</th>\n",
       "      <td>0.035963</td>\n",
       "      <td>1.259689e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sreg</th>\n",
       "      <td>-0.000330</td>\n",
       "      <td>1.307111e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>-0.011639</td>\n",
       "      <td>1.321890e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rdft</th>\n",
       "      <td>0.029677</td>\n",
       "      <td>1.267903e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      profit_R2    profit_MSE\n",
       "kreg   0.001669  1.304500e+08\n",
       "lreg   0.038859  1.255904e+08\n",
       "rdge   0.029830  1.267703e+08\n",
       "lass   0.035963  1.259689e+08\n",
       "sreg  -0.000330  1.307111e+08\n",
       "tree  -0.011639  1.321890e+08\n",
       "rdft   0.029677  1.267903e+08"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores1 = []\n",
    "scores2 = []\n",
    "\n",
    "for item in models:\n",
    "    item.fit(x_tr1,y_tr1)\n",
    "    pred = item.predict(x_te1)\n",
    "    scores1.append(r2_score(y_te1,pred))\n",
    "    scores2.append(mean_squared_error(y_te1,pred))\n",
    "\n",
    "scores1 = pd.DataFrame(scores1)\n",
    "scores2 = pd.DataFrame(scores2)\n",
    "scores1 = scores1.set_index([model_idx])\n",
    "scores2 = scores2.set_index([model_idx])\n",
    "scores1.columns = ['profit_R2']\n",
    "scores2.columns = ['profit_MSE']\n",
    "\n",
    "score_Y1 = pd.concat([scores1,scores2], axis = 1)\n",
    "score_Y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary for y2 - revenue\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "kreg = KNeighborsRegressor(n_neighbors=13)\n",
    "lreg = LinearRegression()\n",
    "rdge = Ridge(alpha=0.01)\n",
    "lass = LassoCV(cv=5)\n",
    "sreg = SVR(kernel='rbf', C=100,  epsilon=1, gamma=0.1)\n",
    "tree = DecisionTreeRegressor(splitter='best', max_depth=2, max_leaf_nodes=5, random_state=0)\n",
    "rdft = RandomForestRegressor(n_estimators=15, max_leaf_nodes=10, random_state=0)\n",
    "\n",
    "models    = [kreg,lreg,rdge,lass,sreg,tree,rdft]\n",
    "model_idx = ['kreg','lreg','rdge','lass','sreg','tree','rdft']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>revenue_R2</th>\n",
       "      <th>revenue_MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>kreg</th>\n",
       "      <td>0.123119</td>\n",
       "      <td>1.834999e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lreg</th>\n",
       "      <td>-0.122933</td>\n",
       "      <td>2.349899e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rdge</th>\n",
       "      <td>-0.116854</td>\n",
       "      <td>2.337178e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lass</th>\n",
       "      <td>-0.116853</td>\n",
       "      <td>2.337177e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sreg</th>\n",
       "      <td>-0.005040</td>\n",
       "      <td>2.103192e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>-0.092311</td>\n",
       "      <td>2.285819e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rdft</th>\n",
       "      <td>-0.037475</td>\n",
       "      <td>2.171066e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      revenue_R2   revenue_MSE\n",
       "kreg    0.123119  1.834999e+08\n",
       "lreg   -0.122933  2.349899e+08\n",
       "rdge   -0.116854  2.337178e+08\n",
       "lass   -0.116853  2.337177e+08\n",
       "sreg   -0.005040  2.103192e+08\n",
       "tree   -0.092311  2.285819e+08\n",
       "rdft   -0.037475  2.171066e+08"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores1 = []\n",
    "scores2 = []\n",
    "\n",
    "for item in models:\n",
    "    item.fit(x_tr2,y_tr2)\n",
    "    pred = item.predict(x_te2)\n",
    "    scores1.append(r2_score(y_te2,pred))\n",
    "    scores2.append(mean_squared_error(y_te2,pred))\n",
    "\n",
    "scores1 = pd.DataFrame(scores1)\n",
    "scores2 = pd.DataFrame(scores2)\n",
    "scores1 = scores1.set_index([model_idx])\n",
    "scores2 = scores2.set_index([model_idx])\n",
    "scores1.columns = ['revenue_R2']\n",
    "scores2.columns = ['revenue_MSE']\n",
    "\n",
    "score_Y2 = pd.concat([scores1,scores2], axis = 1)\n",
    "score_Y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary for y3 - log revenue\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "kreg = KNeighborsRegressor(n_neighbors=31)\n",
    "lreg = LinearRegression()\n",
    "rdge = Ridge(alpha=1)\n",
    "lass = LassoCV(cv=5)\n",
    "sreg = SVR(kernel='rbf', C=100,  epsilon=1, gamma=0.1)\n",
    "tree = DecisionTreeRegressor(splitter='best', max_depth=3, max_leaf_nodes=20, random_state=0)\n",
    "rdft = RandomForestRegressor(n_estimators=13, max_leaf_nodes=20, random_state=0)\n",
    "\n",
    "models    = [kreg,lreg,rdge,lass,sreg,tree,rdft]\n",
    "model_idx = ['kreg','lreg','rdge','lass','sreg','tree','rdft']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logrev_R2</th>\n",
       "      <th>logrev_MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>kreg</th>\n",
       "      <td>0.105540</td>\n",
       "      <td>3.276310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lreg</th>\n",
       "      <td>-0.163622</td>\n",
       "      <td>4.262220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rdge</th>\n",
       "      <td>-0.105770</td>\n",
       "      <td>4.050314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lass</th>\n",
       "      <td>-0.064853</td>\n",
       "      <td>3.900440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sreg</th>\n",
       "      <td>-0.164277</td>\n",
       "      <td>4.264619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>0.078734</td>\n",
       "      <td>3.374495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rdft</th>\n",
       "      <td>0.119694</td>\n",
       "      <td>3.224465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      logrev_R2  logrev_MSE\n",
       "kreg   0.105540    3.276310\n",
       "lreg  -0.163622    4.262220\n",
       "rdge  -0.105770    4.050314\n",
       "lass  -0.064853    3.900440\n",
       "sreg  -0.164277    4.264619\n",
       "tree   0.078734    3.374495\n",
       "rdft   0.119694    3.224465"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores1 = []\n",
    "scores2 = []\n",
    "\n",
    "for item in models:\n",
    "    item.fit(x_tr3,y_tr3)\n",
    "    pred = item.predict(x_te3)\n",
    "    scores1.append(r2_score(y_te3,pred))\n",
    "    scores2.append(mean_squared_error(y_te3,pred))\n",
    "\n",
    "scores1 = pd.DataFrame(scores1)\n",
    "scores2 = pd.DataFrame(scores2)\n",
    "scores1 = scores1.set_index([model_idx])\n",
    "scores2 = scores2.set_index([model_idx])\n",
    "scores1.columns = ['logrev_R2']\n",
    "scores2.columns = ['logrev_MSE']\n",
    "\n",
    "score_Y3 = pd.concat([scores1,scores2], axis = 1)\n",
    "score_Y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try mlp\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# define model\n",
    "sque = Sequential()\n",
    "sque.add(Dense(15, input_dim=15, kernel_initializer='normal', activation='relu'))\n",
    "sque.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
    "sque.add(Dense(1, kernel_initializer='normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "sque.compile(loss='mse',optimizer='adam',metrics = ['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "def grid_keras():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(15, input_dim=15, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mse',optimizer='adam',metrics = ['mse'])\n",
    "    return model\n",
    "\n",
    "keras_reg = KerasRegressor(build_fn = grid_keras, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\STU\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "      <th>param1</th>\n",
       "      <th>param2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Y1</th>\n",
       "      <td>-7.110497e+06</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y2</th>\n",
       "      <td>-7.860344e+07</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y3</th>\n",
       "      <td>-2.271835e+00</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          scores  param1  param2\n",
       "Y1 -7.110497e+06       5     200\n",
       "Y2 -7.860344e+07       5     200\n",
       "Y3 -2.271835e+00       5     200"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keras grid\n",
    "grid_scores = []\n",
    "grid_params = []\n",
    "\n",
    "param_grid = {'batch_size': [5,10,20,50,100],\n",
    "              'epochs'    : [50,100,200]}\n",
    "\n",
    "for (x,y) in XY_list:\n",
    "    grid = GridSearchCV(keras_reg, param_grid, cv=5)\n",
    "    grid.fit(x,y)\n",
    "    grid_scores.append(grid.best_score_)\n",
    "    grid_params.append(grid.best_params_)\n",
    "\n",
    "grid_scores = pd.DataFrame(grid_scores)\n",
    "grid_params = pd.DataFrame(grid_params)\n",
    "grid_scores = grid_scores.set_index([Y_list_idx])\n",
    "grid_params = grid_params.set_index([Y_list_idx])\n",
    "grid_scores.columns = ['scores']\n",
    "grid_params.columns = ['param1','param2']\n",
    "\n",
    "kera_grid = pd.concat([grid_scores,grid_params], axis = 1)\n",
    "kera_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "6692/6692 [==============================] - 12s 2ms/step - loss: 7705259.3565 - mean_squared_error: 7705259.3565\n",
      "Epoch 2/200\n",
      "6692/6692 [==============================] - 5s 731us/step - loss: 7610454.7535 - mean_squared_error: 7610454.7535\n",
      "Epoch 3/200\n",
      "6692/6692 [==============================] - 5s 757us/step - loss: 7529801.4086 - mean_squared_error: 7529801.4086\n",
      "Epoch 4/200\n",
      "6692/6692 [==============================] - 5s 780us/step - loss: 7503037.7006 - mean_squared_error: 7503037.7006\n",
      "Epoch 5/200\n",
      "6692/6692 [==============================] - 5s 794us/step - loss: 7488019.8530 - mean_squared_error: 7488019.8530\n",
      "Epoch 6/200\n",
      "6692/6692 [==============================] - 5s 709us/step - loss: 7478820.2235 - mean_squared_error: 7478820.2235\n",
      "Epoch 7/200\n",
      "6692/6692 [==============================] - 4s 665us/step - loss: 7470051.7745 - mean_squared_error: 7470051.7745\n",
      "Epoch 8/200\n",
      "6692/6692 [==============================] - 4s 652us/step - loss: 7462439.1706 - mean_squared_error: 7462439.1706\n",
      "Epoch 9/200\n",
      "6692/6692 [==============================] - 4s 656us/step - loss: 7454750.9616 - mean_squared_error: 7454750.9616\n",
      "Epoch 10/200\n",
      "6692/6692 [==============================] - 4s 648us/step - loss: 7447158.2341 - mean_squared_error: 7447158.2341\n",
      "Epoch 11/200\n",
      "6692/6692 [==============================] - 4s 652us/step - loss: 7439435.6700 - mean_squared_error: 7439435.6700\n",
      "Epoch 12/200\n",
      "6692/6692 [==============================] - 5s 810us/step - loss: 7432094.9610 - mean_squared_error: 7432094.9610\n",
      "Epoch 13/200\n",
      "6692/6692 [==============================] - 5s 746us/step - loss: 7425037.3180 - mean_squared_error: 7425037.3180\n",
      "Epoch 14/200\n",
      "6692/6692 [==============================] - 5s 760us/step - loss: 7417999.6336 - mean_squared_error: 7417999.6336\n",
      "Epoch 15/200\n",
      "6692/6692 [==============================] - 5s 743us/step - loss: 7410001.6474 - mean_squared_error: 7410001.6474\n",
      "Epoch 16/200\n",
      "6692/6692 [==============================] - 5s 752us/step - loss: 7402684.9241 - mean_squared_error: 7402684.9241\n",
      "Epoch 17/200\n",
      "6692/6692 [==============================] - 5s 749us/step - loss: 7393665.8824 - mean_squared_error: 7393665.8824\n",
      "Epoch 18/200\n",
      "6692/6692 [==============================] - 5s 757us/step - loss: 7382419.1806 - mean_squared_error: 7382419.1806\n",
      "Epoch 19/200\n",
      "6692/6692 [==============================] - 5s 751us/step - loss: 7373651.1174 - mean_squared_error: 7373651.1174\n",
      "Epoch 20/200\n",
      "6692/6692 [==============================] - 5s 748us/step - loss: 7364749.9976 - mean_squared_error: 7364749.9976\n",
      "Epoch 21/200\n",
      "6692/6692 [==============================] - 5s 744us/step - loss: 7355792.0260 - mean_squared_error: 7355792.0260\n",
      "Epoch 22/200\n",
      "6692/6692 [==============================] - 5s 803us/step - loss: 7345582.1648 - mean_squared_error: 7345582.1648\n",
      "Epoch 23/200\n",
      "6692/6692 [==============================] - 5s 785us/step - loss: 7336580.4720 - mean_squared_error: 7336580.4720\n",
      "Epoch 24/200\n",
      "6692/6692 [==============================] - 5s 758us/step - loss: 7326037.5484 - mean_squared_error: 7326037.5484\n",
      "Epoch 25/200\n",
      "6692/6692 [==============================] - 6s 824us/step - loss: 7315280.9543 - mean_squared_error: 7315280.9543\n",
      "Epoch 26/200\n",
      "6692/6692 [==============================] - 6s 858us/step - loss: 7305438.1615 - mean_squared_error: 7305438.1615\n",
      "Epoch 27/200\n",
      "6692/6692 [==============================] - 6s 903us/step - loss: 7296617.6125 - mean_squared_error: 7296617.6125\n",
      "Epoch 28/200\n",
      "6692/6692 [==============================] - 6s 887us/step - loss: 7284717.8774 - mean_squared_error: 7284717.8774\n",
      "Epoch 29/200\n",
      "6692/6692 [==============================] - 6s 849us/step - loss: 7274921.5578 - mean_squared_error: 7274921.5578\n",
      "Epoch 30/200\n",
      "6692/6692 [==============================] - 6s 899us/step - loss: 7264602.9835 - mean_squared_error: 7264602.9835\n",
      "Epoch 31/200\n",
      "6692/6692 [==============================] - 6s 894us/step - loss: 7255661.8463 - mean_squared_error: 7255661.8463\n",
      "Epoch 32/200\n",
      "6692/6692 [==============================] - 6s 900us/step - loss: 7246731.3887 - mean_squared_error: 7246731.3887\n",
      "Epoch 33/200\n",
      "6692/6692 [==============================] - 6s 868us/step - loss: 7237834.2153 - mean_squared_error: 7237834.2153\n",
      "Epoch 34/200\n",
      "6692/6692 [==============================] - 6s 871us/step - loss: 7227773.9581 - mean_squared_error: 7227773.9581\n",
      "Epoch 35/200\n",
      "6692/6692 [==============================] - 6s 822us/step - loss: 7221808.4412 - mean_squared_error: 7221808.4412\n",
      "Epoch 36/200\n",
      "6692/6692 [==============================] - 6s 828us/step - loss: 7211992.9722 - mean_squared_error: 7211992.9722\n",
      "Epoch 37/200\n",
      "6692/6692 [==============================] - 5s 771us/step - loss: 7205170.8078 - mean_squared_error: 7205170.8078\n",
      "Epoch 38/200\n",
      "6692/6692 [==============================] - 5s 801us/step - loss: 7196938.0306 - mean_squared_error: 7196938.0306\n",
      "Epoch 39/200\n",
      "6692/6692 [==============================] - 5s 784us/step - loss: 7187923.6869 - mean_squared_error: 7187923.6869\n",
      "Epoch 40/200\n",
      "6692/6692 [==============================] - 5s 791us/step - loss: 7179982.9901 - mean_squared_error: 7179982.9901\n",
      "Epoch 41/200\n",
      "6692/6692 [==============================] - 5s 781us/step - loss: 7173398.8466 - mean_squared_error: 7173398.8466\n",
      "Epoch 42/200\n",
      "6692/6692 [==============================] - 5s 775us/step - loss: 7164783.8556 - mean_squared_error: 7164783.8556\n",
      "Epoch 43/200\n",
      "6692/6692 [==============================] - 5s 780us/step - loss: 7158149.7121 - mean_squared_error: 7158149.7121\n",
      "Epoch 44/200\n",
      "6692/6692 [==============================] - 5s 791us/step - loss: 7153133.4535 - mean_squared_error: 7153133.4535\n",
      "Epoch 45/200\n",
      "6692/6692 [==============================] - 6s 854us/step - loss: 7147428.0338 - mean_squared_error: 7147428.0338\n",
      "Epoch 46/200\n",
      "6692/6692 [==============================] - 5s 782us/step - loss: 7140809.1106 - mean_squared_error: 7140809.1106\n",
      "Epoch 47/200\n",
      "6692/6692 [==============================] - 5s 790us/step - loss: 7136829.0539 - mean_squared_error: 7136829.0539\n",
      "Epoch 48/200\n",
      "6692/6692 [==============================] - 5s 786us/step - loss: 7131208.3111 - mean_squared_error: 7131208.3111\n",
      "Epoch 49/200\n",
      "6692/6692 [==============================] - 5s 793us/step - loss: 7127166.0993 - mean_squared_error: 7127166.0993\n",
      "Epoch 50/200\n",
      "6692/6692 [==============================] - 5s 757us/step - loss: 7122591.1065 - mean_squared_error: 7122591.1065\n",
      "Epoch 51/200\n",
      "6692/6692 [==============================] - 5s 754us/step - loss: 7119859.5777 - mean_squared_error: 7119859.5777\n",
      "Epoch 52/200\n",
      "6692/6692 [==============================] - 5s 755us/step - loss: 7115580.2133 - mean_squared_error: 7115580.2133\n",
      "Epoch 53/200\n",
      "6692/6692 [==============================] - 5s 755us/step - loss: 7112860.1891 - mean_squared_error: 7112860.1891\n",
      "Epoch 54/200\n",
      "6692/6692 [==============================] - 5s 755us/step - loss: 7109429.4987 - mean_squared_error: 7109429.4987\n",
      "Epoch 55/200\n",
      "6692/6692 [==============================] - 5s 756us/step - loss: 7106819.7683 - mean_squared_error: 7106819.7683\n",
      "Epoch 56/200\n",
      "6692/6692 [==============================] - 5s 755us/step - loss: 7104208.1252 - mean_squared_error: 7104208.1252\n",
      "Epoch 57/200\n",
      "6692/6692 [==============================] - 5s 757us/step - loss: 7100486.3736 - mean_squared_error: 7100486.3736\n",
      "Epoch 58/200\n",
      "6692/6692 [==============================] - 5s 756us/step - loss: 7099830.6573 - mean_squared_error: 7099830.6573\n",
      "Epoch 59/200\n",
      "6692/6692 [==============================] - 5s 757us/step - loss: 7097713.8100 - mean_squared_error: 7097713.8100\n",
      "Epoch 60/200\n",
      "6692/6692 [==============================] - 5s 758us/step - loss: 7094660.1796 - mean_squared_error: 7094660.1796\n",
      "Epoch 61/200\n",
      "6692/6692 [==============================] - 5s 765us/step - loss: 7091529.2287 - mean_squared_error: 7091529.2287\n",
      "Epoch 62/200\n",
      "6692/6692 [==============================] - 5s 764us/step - loss: 7091506.6473 - mean_squared_error: 7091506.6473\n",
      "Epoch 63/200\n",
      "6692/6692 [==============================] - 5s 774us/step - loss: 7089138.7826 - mean_squared_error: 7089138.7826\n",
      "Epoch 64/200\n",
      "6692/6692 [==============================] - 6s 837us/step - loss: 7087257.1608 - mean_squared_error: 7087257.1608\n",
      "Epoch 65/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6692/6692 [==============================] - 5s 735us/step - loss: 7085548.3106 - mean_squared_error: 7085548.3106\n",
      "Epoch 66/200\n",
      "6692/6692 [==============================] - 5s 733us/step - loss: 7083731.4802 - mean_squared_error: 7083731.4802\n",
      "Epoch 67/200\n",
      "6692/6692 [==============================] - 5s 729us/step - loss: 7084026.7211 - mean_squared_error: 7084026.7211\n",
      "Epoch 68/200\n",
      "6692/6692 [==============================] - 5s 731us/step - loss: 7080568.1724 - mean_squared_error: 7080568.1724\n",
      "Epoch 69/200\n",
      "6692/6692 [==============================] - 5s 741us/step - loss: 7079179.7062 - mean_squared_error: 7079179.7062\n",
      "Epoch 70/200\n",
      "6692/6692 [==============================] - 5s 739us/step - loss: 7078069.6789 - mean_squared_error: 7078069.6789\n",
      "Epoch 71/200\n",
      "6692/6692 [==============================] - 5s 746us/step - loss: 7077083.6246 - mean_squared_error: 7077083.6246\n",
      "Epoch 72/200\n",
      "6692/6692 [==============================] - 5s 734us/step - loss: 7075152.7683 - mean_squared_error: 7075152.7683\n",
      "Epoch 73/200\n",
      "6692/6692 [==============================] - 5s 742us/step - loss: 7072767.4947 - mean_squared_error: 7072767.4947\n",
      "Epoch 74/200\n",
      "6692/6692 [==============================] - 5s 734us/step - loss: 7073269.9705 - mean_squared_error: 7073269.9705\n",
      "Epoch 75/200\n",
      "6692/6692 [==============================] - 5s 732us/step - loss: 7071828.3291 - mean_squared_error: 7071828.3291\n",
      "Epoch 76/200\n",
      "6692/6692 [==============================] - 5s 737us/step - loss: 7068109.6533 - mean_squared_error: 7068109.6533\n",
      "Epoch 77/200\n",
      "6692/6692 [==============================] - 5s 742us/step - loss: 7068769.7594 - mean_squared_error: 7068769.7594\n",
      "Epoch 78/200\n",
      "6692/6692 [==============================] - 5s 738us/step - loss: 7066927.1796 - mean_squared_error: 7066927.1796\n",
      "Epoch 79/200\n",
      "6692/6692 [==============================] - 5s 735us/step - loss: 7066805.7647 - mean_squared_error: 7066805.7647\n",
      "Epoch 80/200\n",
      "6692/6692 [==============================] - 5s 737us/step - loss: 7062976.5692 - mean_squared_error: 7062976.5692\n",
      "Epoch 81/200\n",
      "6692/6692 [==============================] - 5s 735us/step - loss: 7063849.0053 - mean_squared_error: 7063849.0053\n",
      "Epoch 82/200\n",
      "6692/6692 [==============================] - 5s 737us/step - loss: 7062356.0972 - mean_squared_error: 7062356.0972\n",
      "Epoch 83/200\n",
      "6692/6692 [==============================] - 5s 737us/step - loss: 7060865.9287 - mean_squared_error: 7060865.9287\n",
      "Epoch 84/200\n",
      "6692/6692 [==============================] - 5s 740us/step - loss: 7059870.2094 - mean_squared_error: 7059870.2094\n",
      "Epoch 85/200\n",
      "6692/6692 [==============================] - 5s 736us/step - loss: 7059115.3857 - mean_squared_error: 7059115.3857\n",
      "Epoch 86/200\n",
      "6692/6692 [==============================] - 5s 750us/step - loss: 7059049.1431 - mean_squared_error: 7059049.1431\n",
      "Epoch 87/200\n",
      "6692/6692 [==============================] - 5s 742us/step - loss: 7056239.6641 - mean_squared_error: 7056239.6641\n",
      "Epoch 88/200\n",
      "6692/6692 [==============================] - 5s 742us/step - loss: 7054706.2246 - mean_squared_error: 7054706.2246\n",
      "Epoch 89/200\n",
      "6692/6692 [==============================] - 5s 741us/step - loss: 7054350.2285 - mean_squared_error: 7054350.2285\n",
      "Epoch 90/200\n",
      "6692/6692 [==============================] - 5s 742us/step - loss: 7053700.6055 - mean_squared_error: 7053700.6055\n",
      "Epoch 91/200\n",
      "6692/6692 [==============================] - 5s 741us/step - loss: 7051623.2756 - mean_squared_error: 7051623.2756\n",
      "Epoch 92/200\n",
      "6692/6692 [==============================] - 5s 742us/step - loss: 7048817.4281 - mean_squared_error: 7048817.4281\n",
      "Epoch 93/200\n",
      "6692/6692 [==============================] - 5s 742us/step - loss: 7050341.6594 - mean_squared_error: 7050341.6594\n",
      "Epoch 94/200\n",
      "6692/6692 [==============================] - 5s 744us/step - loss: 7049461.0659 - mean_squared_error: 7049461.0659\n",
      "Epoch 95/200\n",
      "6692/6692 [==============================] - 5s 747us/step - loss: 7047556.1894 - mean_squared_error: 7047556.1894\n",
      "Epoch 96/200\n",
      "6692/6692 [==============================] - 5s 746us/step - loss: 7046975.2857 - mean_squared_error: 7046975.2857\n",
      "Epoch 97/200\n",
      "6692/6692 [==============================] - 5s 760us/step - loss: 7046492.7061 - mean_squared_error: 7046492.7061\n",
      "Epoch 98/200\n",
      "6692/6692 [==============================] - 5s 755us/step - loss: 7045598.2364 - mean_squared_error: 7045598.2364\n",
      "Epoch 99/200\n",
      "6692/6692 [==============================] - 5s 744us/step - loss: 7043928.2479 - mean_squared_error: 7043928.2479\n",
      "Epoch 100/200\n",
      "6692/6692 [==============================] - 5s 747us/step - loss: 7041233.8008 - mean_squared_error: 7041233.8008\n",
      "Epoch 101/200\n",
      "6692/6692 [==============================] - 5s 747us/step - loss: 7041830.7146 - mean_squared_error: 7041830.7146\n",
      "Epoch 102/200\n",
      "6692/6692 [==============================] - 5s 749us/step - loss: 7041060.5185 - mean_squared_error: 7041060.5185\n",
      "Epoch 103/200\n",
      "6692/6692 [==============================] - 5s 748us/step - loss: 7040770.5365 - mean_squared_error: 7040770.5365\n",
      "Epoch 104/200\n",
      "6692/6692 [==============================] - 5s 747us/step - loss: 7038212.6266 - mean_squared_error: 7038212.6266\n",
      "Epoch 105/200\n",
      "6692/6692 [==============================] - 5s 745us/step - loss: 7036226.5537 - mean_squared_error: 7036226.5537\n",
      "Epoch 106/200\n",
      "6692/6692 [==============================] - 5s 747us/step - loss: 7036946.7945 - mean_squared_error: 7036946.7945\n",
      "Epoch 107/200\n",
      "6692/6692 [==============================] - 5s 747us/step - loss: 7035730.6899 - mean_squared_error: 7035730.6899\n",
      "Epoch 108/200\n",
      "6692/6692 [==============================] - 5s 748us/step - loss: 7035090.4235 - mean_squared_error: 7035090.4235\n",
      "Epoch 109/200\n",
      "6692/6692 [==============================] - 5s 748us/step - loss: 7034108.4340 - mean_squared_error: 7034108.4340\n",
      "Epoch 110/200\n",
      "6692/6692 [==============================] - 5s 760us/step - loss: 7033376.1019 - mean_squared_error: 7033376.1019\n",
      "Epoch 111/200\n",
      "6692/6692 [==============================] - 5s 750us/step - loss: 7031522.0305 - mean_squared_error: 7031522.0305\n",
      "Epoch 112/200\n",
      "6692/6692 [==============================] - 5s 749us/step - loss: 7031535.0309 - mean_squared_error: 7031535.0309\n",
      "Epoch 113/200\n",
      "6692/6692 [==============================] - 5s 749us/step - loss: 7029596.0667 - mean_squared_error: 7029596.0667\n",
      "Epoch 114/200\n",
      "6692/6692 [==============================] - 5s 748us/step - loss: 7030213.9853 - mean_squared_error: 7030213.9853\n",
      "Epoch 115/200\n",
      "6692/6692 [==============================] - 5s 749us/step - loss: 7028159.0957 - mean_squared_error: 7028159.0957\n",
      "Epoch 116/200\n",
      "6692/6692 [==============================] - 5s 750us/step - loss: 7026882.7720 - mean_squared_error: 7026882.7720\n",
      "Epoch 117/200\n",
      "6692/6692 [==============================] - 5s 751us/step - loss: 7026407.6821 - mean_squared_error: 7026407.6821\n",
      "Epoch 118/200\n",
      "6692/6692 [==============================] - 5s 751us/step - loss: 7025162.9666 - mean_squared_error: 7025162.9666\n",
      "Epoch 119/200\n",
      "6692/6692 [==============================] - 5s 751us/step - loss: 7024528.0768 - mean_squared_error: 7024528.0768\n",
      "Epoch 120/200\n",
      "6692/6692 [==============================] - 5s 751us/step - loss: 7023169.7148 - mean_squared_error: 7023169.7148\n",
      "Epoch 121/200\n",
      "6692/6692 [==============================] - 5s 753us/step - loss: 7022023.9264 - mean_squared_error: 7022023.9264\n",
      "Epoch 122/200\n",
      "6692/6692 [==============================] - 5s 758us/step - loss: 7021028.0369 - mean_squared_error: 7021028.0369\n",
      "Epoch 123/200\n",
      "6692/6692 [==============================] - 5s 750us/step - loss: 7020126.4721 - mean_squared_error: 7020126.4721\n",
      "Epoch 124/200\n",
      "6692/6692 [==============================] - 5s 756us/step - loss: 7018137.0111 - mean_squared_error: 7018137.0111\n",
      "Epoch 125/200\n",
      "6692/6692 [==============================] - 5s 754us/step - loss: 7018954.7339 - mean_squared_error: 7018954.7339\n",
      "Epoch 126/200\n",
      "6692/6692 [==============================] - 5s 753us/step - loss: 7016637.5486 - mean_squared_error: 7016637.5486\n",
      "Epoch 127/200\n",
      "6692/6692 [==============================] - 5s 751us/step - loss: 7016966.2447 - mean_squared_error: 7016966.2447\n",
      "Epoch 128/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6692/6692 [==============================] - 5s 728us/step - loss: 7015491.0383 - mean_squared_error: 7015491.0383\n",
      "Epoch 129/200\n",
      "6692/6692 [==============================] - 5s 727us/step - loss: 7012906.4761 - mean_squared_error: 7012906.4761\n",
      "Epoch 130/200\n",
      "6692/6692 [==============================] - 5s 730us/step - loss: 7013299.9423 - mean_squared_error: 7013299.9423\n",
      "Epoch 131/200\n",
      "6692/6692 [==============================] - 5s 746us/step - loss: 7013159.6210 - mean_squared_error: 7013159.6210\n",
      "Epoch 132/200\n",
      "6692/6692 [==============================] - 5s 729us/step - loss: 7010873.7561 - mean_squared_error: 7010873.7561\n",
      "Epoch 133/200\n",
      "6692/6692 [==============================] - 5s 733us/step - loss: 7009990.2371 - mean_squared_error: 7009990.2371\n",
      "Epoch 134/200\n",
      "6692/6692 [==============================] - 5s 744us/step - loss: 7009442.9301 - mean_squared_error: 7009442.9301\n",
      "Epoch 135/200\n",
      "6692/6692 [==============================] - 5s 736us/step - loss: 7007449.6061 - mean_squared_error: 7007449.6061\n",
      "Epoch 136/200\n",
      "6692/6692 [==============================] - 5s 739us/step - loss: 7007344.9973 - mean_squared_error: 7007344.9973\n",
      "Epoch 137/200\n",
      "6692/6692 [==============================] - 5s 737us/step - loss: 7005168.6960 - mean_squared_error: 7005168.6960\n",
      "Epoch 138/200\n",
      "6692/6692 [==============================] - 5s 732us/step - loss: 7004515.0668 - mean_squared_error: 7004515.0668\n",
      "Epoch 139/200\n",
      "6692/6692 [==============================] - 5s 735us/step - loss: 7003777.2090 - mean_squared_error: 7003777.2090\n",
      "Epoch 140/200\n",
      "6692/6692 [==============================] - 5s 733us/step - loss: 7003443.3693 - mean_squared_error: 7003443.3693\n",
      "Epoch 141/200\n",
      "6692/6692 [==============================] - 5s 733us/step - loss: 7002418.3451 - mean_squared_error: 7002418.3451\n",
      "Epoch 142/200\n",
      "6692/6692 [==============================] - 5s 748us/step - loss: 7001334.6977 - mean_squared_error: 7001334.6977\n",
      "Epoch 143/200\n",
      "6692/6692 [==============================] - 5s 812us/step - loss: 6999842.5767 - mean_squared_error: 6999842.5767\n",
      "Epoch 144/200\n",
      "6692/6692 [==============================] - 6s 823us/step - loss: 6999973.5216 - mean_squared_error: 6999973.5216\n",
      "Epoch 145/200\n",
      "6692/6692 [==============================] - 6s 880us/step - loss: 6998584.9169 - mean_squared_error: 6998584.9169\n",
      "Epoch 146/200\n",
      "6692/6692 [==============================] - 6s 861us/step - loss: 6997168.4538 - mean_squared_error: 6997168.4538\n",
      "Epoch 147/200\n",
      "6692/6692 [==============================] - 6s 904us/step - loss: 6997426.4328 - mean_squared_error: 6997426.4328\n",
      "Epoch 148/200\n",
      "6692/6692 [==============================] - 5s 737us/step - loss: 6994650.3076 - mean_squared_error: 6994650.3076\n",
      "Epoch 149/200\n",
      "6692/6692 [==============================] - 5s 741us/step - loss: 6994492.5045 - mean_squared_error: 6994492.5045\n",
      "Epoch 150/200\n",
      "6692/6692 [==============================] - 5s 736us/step - loss: 6993394.0273 - mean_squared_error: 6993394.0273\n",
      "Epoch 151/200\n",
      "6692/6692 [==============================] - 5s 735us/step - loss: 6994509.9790 - mean_squared_error: 6994509.9790\n",
      "Epoch 152/200\n",
      "6692/6692 [==============================] - 5s 740us/step - loss: 6992970.1559 - mean_squared_error: 6992970.1559\n",
      "Epoch 153/200\n",
      "6692/6692 [==============================] - 5s 736us/step - loss: 6992079.8516 - mean_squared_error: 6992079.8516\n",
      "Epoch 154/200\n",
      "6692/6692 [==============================] - 5s 740us/step - loss: 6992328.6770 - mean_squared_error: 6992328.6770\n",
      "Epoch 155/200\n",
      "6692/6692 [==============================] - 5s 739us/step - loss: 6991065.3756 - mean_squared_error: 6991065.3756\n",
      "Epoch 156/200\n",
      "6692/6692 [==============================] - 5s 739us/step - loss: 6989385.6455 - mean_squared_error: 6989385.6455\n",
      "Epoch 157/200\n",
      "6692/6692 [==============================] - 5s 747us/step - loss: 6989211.2774 - mean_squared_error: 6989211.2774\n",
      "Epoch 158/200\n",
      "6692/6692 [==============================] - 5s 752us/step - loss: 6987504.6296 - mean_squared_error: 6987504.6296\n",
      "Epoch 159/200\n",
      "6692/6692 [==============================] - 5s 742us/step - loss: 6986297.7059 - mean_squared_error: 6986297.7059\n",
      "Epoch 160/200\n",
      "6692/6692 [==============================] - 5s 740us/step - loss: 6987660.4194 - mean_squared_error: 6987660.4194\n",
      "Epoch 161/200\n",
      "6692/6692 [==============================] - 5s 742us/step - loss: 6984863.9337 - mean_squared_error: 6984863.9337\n",
      "Epoch 162/200\n",
      "6692/6692 [==============================] - 5s 742us/step - loss: 6984538.7532 - mean_squared_error: 6984538.7532\n",
      "Epoch 163/200\n",
      "6692/6692 [==============================] - 5s 741us/step - loss: 6983889.4043 - mean_squared_error: 6983889.4043\n",
      "Epoch 164/200\n",
      "6692/6692 [==============================] - 5s 744us/step - loss: 6983123.8130 - mean_squared_error: 6983123.8130\n",
      "Epoch 165/200\n",
      "6692/6692 [==============================] - 5s 740us/step - loss: 6982726.8707 - mean_squared_error: 6982726.8707\n",
      "Epoch 166/200\n",
      "6692/6692 [==============================] - 5s 742us/step - loss: 6982258.0995 - mean_squared_error: 6982258.0995\n",
      "Epoch 167/200\n",
      "6692/6692 [==============================] - 5s 741us/step - loss: 6981456.2057 - mean_squared_error: 6981456.2057\n",
      "Epoch 168/200\n",
      "6692/6692 [==============================] - 5s 740us/step - loss: 6982204.4270 - mean_squared_error: 6982204.4270\n",
      "Epoch 169/200\n",
      "6692/6692 [==============================] - 5s 748us/step - loss: 6980729.0678 - mean_squared_error: 6980729.0678\n",
      "Epoch 170/200\n",
      "6692/6692 [==============================] - 5s 742us/step - loss: 6978754.3646 - mean_squared_error: 6978754.3646\n",
      "Epoch 171/200\n",
      "6692/6692 [==============================] - 5s 743us/step - loss: 6979783.7631 - mean_squared_error: 6979783.7631\n",
      "Epoch 172/200\n",
      "6692/6692 [==============================] - 5s 742us/step - loss: 6978568.9351 - mean_squared_error: 6978568.9351\n",
      "Epoch 173/200\n",
      "6692/6692 [==============================] - 5s 743us/step - loss: 6977847.3370 - mean_squared_error: 6977847.3370\n",
      "Epoch 174/200\n",
      "6692/6692 [==============================] - 5s 740us/step - loss: 6977194.7276 - mean_squared_error: 6977194.7276\n",
      "Epoch 175/200\n",
      "6692/6692 [==============================] - 5s 741us/step - loss: 6972702.2636 - mean_squared_error: 6972702.2636\n",
      "Epoch 176/200\n",
      "6692/6692 [==============================] - 5s 742us/step - loss: 6977655.9473 - mean_squared_error: 6977655.9473\n",
      "Epoch 177/200\n",
      "6692/6692 [==============================] - 5s 743us/step - loss: 6974732.2389 - mean_squared_error: 6974732.2389\n",
      "Epoch 178/200\n",
      "6692/6692 [==============================] - 5s 743us/step - loss: 6974567.2305 - mean_squared_error: 6974567.2305\n",
      "Epoch 179/200\n",
      "6692/6692 [==============================] - 5s 743us/step - loss: 6973436.8085 - mean_squared_error: 6973436.8085\n",
      "Epoch 180/200\n",
      "6692/6692 [==============================] - 5s 741us/step - loss: 6972826.3238 - mean_squared_error: 6972826.3238\n",
      "Epoch 181/200\n",
      "6692/6692 [==============================] - 5s 744us/step - loss: 6972589.5617 - mean_squared_error: 6972589.5617\n",
      "Epoch 182/200\n",
      "6692/6692 [==============================] - 5s 756us/step - loss: 6971333.3560 - mean_squared_error: 6971333.3560\n",
      "Epoch 183/200\n",
      "6692/6692 [==============================] - 5s 744us/step - loss: 6971524.0878 - mean_squared_error: 6971524.0878\n",
      "Epoch 184/200\n",
      "6692/6692 [==============================] - 5s 745us/step - loss: 6970107.7045 - mean_squared_error: 6970107.7045\n",
      "Epoch 185/200\n",
      "6692/6692 [==============================] - 5s 749us/step - loss: 6968714.9314 - mean_squared_error: 6968714.9314\n",
      "Epoch 186/200\n",
      "6692/6692 [==============================] - 5s 747us/step - loss: 6969125.1876 - mean_squared_error: 6969125.1876\n",
      "Epoch 187/200\n",
      "6692/6692 [==============================] - 5s 750us/step - loss: 6969041.5750 - mean_squared_error: 6969041.5750\n",
      "Epoch 188/200\n",
      "6692/6692 [==============================] - 5s 748us/step - loss: 6965538.0171 - mean_squared_error: 6965538.0171\n",
      "Epoch 189/200\n",
      "6692/6692 [==============================] - 5s 750us/step - loss: 6967886.7365 - mean_squared_error: 6967886.7365\n",
      "Epoch 190/200\n",
      "6692/6692 [==============================] - 5s 750us/step - loss: 6966477.3998 - mean_squared_error: 6966477.3998\n",
      "Epoch 191/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6692/6692 [==============================] - 5s 743us/step - loss: 6965748.5654 - mean_squared_error: 6965748.5654\n",
      "Epoch 192/200\n",
      "6692/6692 [==============================] - 5s 734us/step - loss: 6964642.3342 - mean_squared_error: 6964642.3342\n",
      "Epoch 193/200\n",
      "6692/6692 [==============================] - 5s 734us/step - loss: 6964006.2626 - mean_squared_error: 6964006.2626\n",
      "Epoch 194/200\n",
      "6692/6692 [==============================] - 5s 741us/step - loss: 6963846.3091 - mean_squared_error: 6963846.3091\n",
      "Epoch 195/200\n",
      "6692/6692 [==============================] - 5s 734us/step - loss: 6963112.0432 - mean_squared_error: 6963112.0432\n",
      "Epoch 196/200\n",
      "6692/6692 [==============================] - 5s 735us/step - loss: 6962527.7949 - mean_squared_error: 6962527.7949\n",
      "Epoch 197/200\n",
      "6692/6692 [==============================] - 5s 735us/step - loss: 6958823.8677 - mean_squared_error: 6958823.8677\n",
      "Epoch 198/200\n",
      "6692/6692 [==============================] - 5s 735us/step - loss: 6961072.1578 - mean_squared_error: 6961072.1578\n",
      "Epoch 199/200\n",
      "6692/6692 [==============================] - 5s 736us/step - loss: 6961210.8088 - mean_squared_error: 6961210.8088\n",
      "Epoch 200/200\n",
      "6692/6692 [==============================] - 5s 737us/step - loss: 6959359.5992 - mean_squared_error: 6959359.5992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27371eaa9e8>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model for Y1\n",
    "sque.fit(x_tr1, y_tr1, epochs=200, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008740762394810364"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluat model for Y1\n",
    "sque_pred1 = sque.predict(x_te1)\n",
    "r2_score(y_te1,sque_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "6692/6692 [==============================] - 5s 733us/step - loss: 96630710.0229 - mean_squared_error: 96630710.0229\n",
      "Epoch 2/200\n",
      "6692/6692 [==============================] - 5s 731us/step - loss: 92117240.5227 - mean_squared_error: 92117240.5227\n",
      "Epoch 3/200\n",
      "6692/6692 [==============================] - 5s 729us/step - loss: 90960127.2908 - mean_squared_error: 90960127.2908\n",
      "Epoch 4/200\n",
      "6692/6692 [==============================] - 5s 731us/step - loss: 90232470.3699 - mean_squared_error: 90232470.3699\n",
      "Epoch 5/200\n",
      "6692/6692 [==============================] - 5s 738us/step - loss: 89593333.6567 - mean_squared_error: 89593333.6567\n",
      "Epoch 6/200\n",
      "6692/6692 [==============================] - 5s 740us/step - loss: 89007034.5036 - mean_squared_error: 89007034.5036\n",
      "Epoch 7/200\n",
      "6692/6692 [==============================] - 5s 733us/step - loss: 88444899.0677 - mean_squared_error: 88444899.0677\n",
      "Epoch 8/200\n",
      "6692/6692 [==============================] - 5s 733us/step - loss: 87895326.6159 - mean_squared_error: 87895326.6159\n",
      "Epoch 9/200\n",
      "6692/6692 [==============================] - 5s 733us/step - loss: 87331394.8257 - mean_squared_error: 87331394.8257\n",
      "Epoch 10/200\n",
      "6692/6692 [==============================] - 5s 735us/step - loss: 86790542.5348 - mean_squared_error: 86790542.5348\n",
      "Epoch 11/200\n",
      "6692/6692 [==============================] - 5s 733us/step - loss: 86277115.4244 - mean_squared_error: 86277115.4244\n",
      "Epoch 12/200\n",
      "6692/6692 [==============================] - 5s 732us/step - loss: 85780201.8740 - mean_squared_error: 85780201.8740\n",
      "Epoch 13/200\n",
      "6692/6692 [==============================] - 5s 734us/step - loss: 85271653.7506 - mean_squared_error: 85271653.7506\n",
      "Epoch 14/200\n",
      "6692/6692 [==============================] - 5s 733us/step - loss: 84770502.3465 - mean_squared_error: 84770502.3465\n",
      "Epoch 15/200\n",
      "6692/6692 [==============================] - 5s 736us/step - loss: 84319055.2991 - mean_squared_error: 84319055.2991\n",
      "Epoch 16/200\n",
      "6692/6692 [==============================] - 5s 733us/step - loss: 83877563.0951 - mean_squared_error: 83877563.0951\n",
      "Epoch 17/200\n",
      "6692/6692 [==============================] - 5s 734us/step - loss: 83475115.1110 - mean_squared_error: 83475115.1110\n",
      "Epoch 18/200\n",
      "6692/6692 [==============================] - 5s 740us/step - loss: 83056540.3307 - mean_squared_error: 83056540.3307\n",
      "Epoch 19/200\n",
      "6692/6692 [==============================] - 5s 736us/step - loss: 82665214.6447 - mean_squared_error: 82665214.6447\n",
      "Epoch 20/200\n",
      "6692/6692 [==============================] - 5s 735us/step - loss: 82311188.9230 - mean_squared_error: 82311188.9230\n",
      "Epoch 21/200\n",
      "6692/6692 [==============================] - 5s 738us/step - loss: 81955340.9241 - mean_squared_error: 81955340.9241\n",
      "Epoch 22/200\n",
      "6692/6692 [==============================] - 5s 737us/step - loss: 81671555.1401 - mean_squared_error: 81671555.1401\n",
      "Epoch 23/200\n",
      "6692/6692 [==============================] - 5s 739us/step - loss: 81399447.7413 - mean_squared_error: 81399447.7413\n",
      "Epoch 24/200\n",
      "6692/6692 [==============================] - 5s 739us/step - loss: 81155350.7139 - mean_squared_error: 81155350.7139\n",
      "Epoch 25/200\n",
      "6692/6692 [==============================] - 5s 741us/step - loss: 80910012.7257 - mean_squared_error: 80910012.7257\n",
      "Epoch 26/200\n",
      "6692/6692 [==============================] - 5s 740us/step - loss: 80701730.6620 - mean_squared_error: 80701730.6620\n",
      "Epoch 27/200\n",
      "6692/6692 [==============================] - 5s 744us/step - loss: 80509713.1299 - mean_squared_error: 80509713.1299\n",
      "Epoch 28/200\n",
      "6692/6692 [==============================] - 5s 742us/step - loss: 80327580.4259 - mean_squared_error: 80327580.4259\n",
      "Epoch 29/200\n",
      "6692/6692 [==============================] - 5s 742us/step - loss: 80156083.7275 - mean_squared_error: 80156083.7275\n",
      "Epoch 30/200\n",
      "6692/6692 [==============================] - 5s 756us/step - loss: 80005169.7798 - mean_squared_error: 80005169.7798\n",
      "Epoch 31/200\n",
      "6692/6692 [==============================] - 5s 747us/step - loss: 79883148.4406 - mean_squared_error: 79883148.4406\n",
      "Epoch 32/200\n",
      "6692/6692 [==============================] - 5s 742us/step - loss: 79759788.3436 - mean_squared_error: 79759788.3436\n",
      "Epoch 33/200\n",
      "6692/6692 [==============================] - 5s 744us/step - loss: 79671329.0918 - mean_squared_error: 79671329.0918\n",
      "Epoch 34/200\n",
      "6692/6692 [==============================] - 5s 744us/step - loss: 79551677.5086 - mean_squared_error: 79551677.5086\n",
      "Epoch 35/200\n",
      "6692/6692 [==============================] - 5s 746us/step - loss: 79447298.1042 - mean_squared_error: 79447298.1042\n",
      "Epoch 36/200\n",
      "6692/6692 [==============================] - 5s 746us/step - loss: 79379452.0422 - mean_squared_error: 79379452.0422\n",
      "Epoch 37/200\n",
      "6692/6692 [==============================] - 5s 749us/step - loss: 79309867.5741 - mean_squared_error: 79309867.5741\n",
      "Epoch 38/200\n",
      "6692/6692 [==============================] - 5s 748us/step - loss: 79240347.9935 - mean_squared_error: 79240347.9935\n",
      "Epoch 39/200\n",
      "6692/6692 [==============================] - 5s 750us/step - loss: 79195746.1605 - mean_squared_error: 79195746.1605\n",
      "Epoch 40/200\n",
      "6692/6692 [==============================] - 5s 747us/step - loss: 79113445.2119 - mean_squared_error: 79113445.2119\n",
      "Epoch 41/200\n",
      "6692/6692 [==============================] - 5s 749us/step - loss: 79050565.4037 - mean_squared_error: 79050565.4037\n",
      "Epoch 42/200\n",
      "6692/6692 [==============================] - 5s 755us/step - loss: 79037299.6836 - mean_squared_error: 79037299.6836\n",
      "Epoch 43/200\n",
      "6692/6692 [==============================] - 5s 749us/step - loss: 78986638.8885 - mean_squared_error: 78986638.8885\n",
      "Epoch 44/200\n",
      "6692/6692 [==============================] - 5s 746us/step - loss: 78945001.3369 - mean_squared_error: 78945001.3369\n",
      "Epoch 45/200\n",
      "6692/6692 [==============================] - 5s 746us/step - loss: 78902612.2482 - mean_squared_error: 78902612.2482\n",
      "Epoch 46/200\n",
      "6692/6692 [==============================] - 5s 749us/step - loss: 78857288.7590 - mean_squared_error: 78857288.7590\n",
      "Epoch 47/200\n",
      "6692/6692 [==============================] - 5s 749us/step - loss: 78855089.1728 - mean_squared_error: 78855089.1728\n",
      "Epoch 48/200\n",
      "6692/6692 [==============================] - 5s 751us/step - loss: 78828948.5884 - mean_squared_error: 78828948.5884\n",
      "Epoch 49/200\n",
      "6692/6692 [==============================] - 5s 751us/step - loss: 78789741.0137 - mean_squared_error: 78789741.0137\n",
      "Epoch 50/200\n",
      "6692/6692 [==============================] - 5s 754us/step - loss: 78753793.0510 - mean_squared_error: 78753793.0510\n",
      "Epoch 51/200\n",
      "6692/6692 [==============================] - 5s 762us/step - loss: 78745717.4948 - mean_squared_error: 78745717.4948\n",
      "Epoch 52/200\n",
      "6692/6692 [==============================] - 5s 754us/step - loss: 78711512.0538 - mean_squared_error: 78711512.0538\n",
      "Epoch 53/200\n",
      "6692/6692 [==============================] - 5s 755us/step - loss: 78658996.9270 - mean_squared_error: 78658996.9270\n",
      "Epoch 54/200\n",
      "6692/6692 [==============================] - 5s 770us/step - loss: 78657122.4265 - mean_squared_error: 78657122.4265\n",
      "Epoch 55/200\n",
      "6692/6692 [==============================] - 5s 752us/step - loss: 78634150.7694 - mean_squared_error: 78634150.7694\n",
      "Epoch 56/200\n",
      "6692/6692 [==============================] - 5s 756us/step - loss: 78585569.5183 - mean_squared_error: 78585569.5183\n",
      "Epoch 57/200\n",
      "6692/6692 [==============================] - 5s 752us/step - loss: 78583978.5302 - mean_squared_error: 78583978.5302\n",
      "Epoch 58/200\n",
      "6692/6692 [==============================] - 5s 751us/step - loss: 78553061.8468 - mean_squared_error: 78553061.8468\n",
      "Epoch 59/200\n",
      "6692/6692 [==============================] - 5s 753us/step - loss: 78526218.8719 - mean_squared_error: 78526218.8719\n",
      "Epoch 60/200\n",
      "6692/6692 [==============================] - 5s 755us/step - loss: 78505677.2853 - mean_squared_error: 78505677.2853\n",
      "Epoch 61/200\n",
      "6692/6692 [==============================] - 5s 755us/step - loss: 78481049.0759 - mean_squared_error: 78481049.0759\n",
      "Epoch 62/200\n",
      "6692/6692 [==============================] - 5s 760us/step - loss: 78463756.5968 - mean_squared_error: 78463756.5968\n",
      "Epoch 63/200\n",
      "6692/6692 [==============================] - 5s 758us/step - loss: 78457561.6229 - mean_squared_error: 78457561.6229\n",
      "Epoch 64/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6692/6692 [==============================] - 5s 728us/step - loss: 78431118.7353 - mean_squared_error: 78431118.7353\n",
      "Epoch 65/200\n",
      "6692/6692 [==============================] - 5s 726us/step - loss: 78402578.8786 - mean_squared_error: 78402578.8786\n",
      "Epoch 66/200\n",
      "6692/6692 [==============================] - 5s 733us/step - loss: 78395116.2320 - mean_squared_error: 78395116.2320\n",
      "Epoch 67/200\n",
      "6692/6692 [==============================] - 5s 732us/step - loss: 78364762.4380 - mean_squared_error: 78364762.4380\n",
      "Epoch 68/200\n",
      "6692/6692 [==============================] - 5s 730us/step - loss: 78341687.3996 - mean_squared_error: 78341687.3996\n",
      "Epoch 69/200\n",
      "6692/6692 [==============================] - 5s 731us/step - loss: 78327317.3311 - mean_squared_error: 78327317.3311\n",
      "Epoch 70/200\n",
      "6692/6692 [==============================] - 5s 732us/step - loss: 78289599.3777 - mean_squared_error: 78289599.3777\n",
      "Epoch 71/200\n",
      "6692/6692 [==============================] - 5s 736us/step - loss: 78295901.9166 - mean_squared_error: 78295901.9166\n",
      "Epoch 72/200\n",
      "6692/6692 [==============================] - 5s 731us/step - loss: 78249737.7937 - mean_squared_error: 78249737.7937\n",
      "Epoch 73/200\n",
      "6692/6692 [==============================] - 5s 733us/step - loss: 78235181.4565 - mean_squared_error: 78235181.4565\n",
      "Epoch 74/200\n",
      "6692/6692 [==============================] - 5s 734us/step - loss: 78196879.8905 - mean_squared_error: 78196879.8905\n",
      "Epoch 75/200\n",
      "6692/6692 [==============================] - 5s 732us/step - loss: 78172856.1880 - mean_squared_error: 78172856.1880\n",
      "Epoch 76/200\n",
      "6692/6692 [==============================] - 5s 736us/step - loss: 78162692.1117 - mean_squared_error: 78162692.1117\n",
      "Epoch 77/200\n",
      "6692/6692 [==============================] - 5s 734us/step - loss: 78129777.8492 - mean_squared_error: 78129777.8492\n",
      "Epoch 78/200\n",
      "6692/6692 [==============================] - 5s 749us/step - loss: 78095504.2229 - mean_squared_error: 78095504.2229\n",
      "Epoch 79/200\n",
      "6692/6692 [==============================] - 5s 735us/step - loss: 78069460.8376 - mean_squared_error: 78069460.8376\n",
      "Epoch 80/200\n",
      "6692/6692 [==============================] - 5s 734us/step - loss: 78056016.1374 - mean_squared_error: 78056016.1374\n",
      "Epoch 81/200\n",
      "6692/6692 [==============================] - 5s 736us/step - loss: 78059059.7642 - mean_squared_error: 78059059.7642\n",
      "Epoch 82/200\n",
      "6692/6692 [==============================] - 5s 735us/step - loss: 78030160.1005 - mean_squared_error: 78030160.1005\n",
      "Epoch 83/200\n",
      "6692/6692 [==============================] - 5s 736us/step - loss: 77988273.4718 - mean_squared_error: 77988273.4718\n",
      "Epoch 84/200\n",
      "6692/6692 [==============================] - 5s 737us/step - loss: 77952099.6581 - mean_squared_error: 77952099.6581\n",
      "Epoch 85/200\n",
      "6692/6692 [==============================] - 5s 737us/step - loss: 77922547.0847 - mean_squared_error: 77922547.0847\n",
      "Epoch 86/200\n",
      "6692/6692 [==============================] - 5s 740us/step - loss: 77910131.6717 - mean_squared_error: 77910131.6717\n",
      "Epoch 87/200\n",
      "6692/6692 [==============================] - 5s 739us/step - loss: 77881660.5020 - mean_squared_error: 77881660.5020\n",
      "Epoch 88/200\n",
      "6692/6692 [==============================] - 5s 741us/step - loss: 77854249.4821 - mean_squared_error: 77854249.4821\n",
      "Epoch 89/200\n",
      "6692/6692 [==============================] - 5s 742us/step - loss: 77827042.6605 - mean_squared_error: 77827042.6605\n",
      "Epoch 90/200\n",
      "6692/6692 [==============================] - 5s 749us/step - loss: 77826366.2145 - mean_squared_error: 77826366.2145\n",
      "Epoch 91/200\n",
      "6692/6692 [==============================] - 5s 739us/step - loss: 77797704.8286 - mean_squared_error: 77797704.8286\n",
      "Epoch 92/200\n",
      "6692/6692 [==============================] - 5s 745us/step - loss: 77776103.7776 - mean_squared_error: 77776103.7776\n",
      "Epoch 93/200\n",
      "6692/6692 [==============================] - 5s 744us/step - loss: 77742897.0083 - mean_squared_error: 77742897.0083\n",
      "Epoch 94/200\n",
      "6692/6692 [==============================] - 5s 744us/step - loss: 77714464.1670 - mean_squared_error: 77714464.1670\n",
      "Epoch 95/200\n",
      "6692/6692 [==============================] - 5s 743us/step - loss: 77708071.5143 - mean_squared_error: 77708071.5143\n",
      "Epoch 96/200\n",
      "6692/6692 [==============================] - 5s 743us/step - loss: 77687761.5010 - mean_squared_error: 77687761.5010\n",
      "Epoch 97/200\n",
      "6692/6692 [==============================] - 5s 741us/step - loss: 77668671.2850 - mean_squared_error: 77668671.2850\n",
      "Epoch 98/200\n",
      "6692/6692 [==============================] - 5s 744us/step - loss: 77616736.8377 - mean_squared_error: 77616736.8377\n",
      "Epoch 99/200\n",
      "6692/6692 [==============================] - 5s 745us/step - loss: 77615010.5619 - mean_squared_error: 77615010.5619\n",
      "Epoch 100/200\n",
      "6692/6692 [==============================] - 5s 745us/step - loss: 77594170.8239 - mean_squared_error: 77594170.8239\n",
      "Epoch 101/200\n",
      "6692/6692 [==============================] - 5s 747us/step - loss: 77562720.8489 - mean_squared_error: 77562720.8489\n",
      "Epoch 102/200\n",
      "6692/6692 [==============================] - 5s 759us/step - loss: 77539254.9276 - mean_squared_error: 77539254.9276\n",
      "Epoch 103/200\n",
      "6692/6692 [==============================] - 5s 750us/step - loss: 77511711.6360 - mean_squared_error: 77511711.6360\n",
      "Epoch 104/200\n",
      "6692/6692 [==============================] - 5s 745us/step - loss: 77492282.1968 - mean_squared_error: 77492282.1968\n",
      "Epoch 105/200\n",
      "6692/6692 [==============================] - 5s 747us/step - loss: 77475517.1967 - mean_squared_error: 77475517.1967\n",
      "Epoch 106/200\n",
      "6692/6692 [==============================] - 5s 749us/step - loss: 77461138.1640 - mean_squared_error: 77461138.1640\n",
      "Epoch 107/200\n",
      "6692/6692 [==============================] - 5s 748us/step - loss: 77438147.7123 - mean_squared_error: 77438147.7123\n",
      "Epoch 108/200\n",
      "6692/6692 [==============================] - 5s 747us/step - loss: 77421158.6246 - mean_squared_error: 77421158.6246\n",
      "Epoch 109/200\n",
      "6692/6692 [==============================] - 5s 745us/step - loss: 77400803.2214 - mean_squared_error: 77400803.2214\n",
      "Epoch 110/200\n",
      "6692/6692 [==============================] - 5s 745us/step - loss: 77380598.4304 - mean_squared_error: 77380598.4304\n",
      "Epoch 111/200\n",
      "6692/6692 [==============================] - 5s 768us/step - loss: 77365066.6296 - mean_squared_error: 77365066.6296\n",
      "Epoch 112/200\n",
      "6692/6692 [==============================] - 5s 746us/step - loss: 77329337.1933 - mean_squared_error: 77329337.1933\n",
      "Epoch 113/200\n",
      "6692/6692 [==============================] - 5s 749us/step - loss: 77314324.0322 - mean_squared_error: 77314324.0322\n",
      "Epoch 114/200\n",
      "6692/6692 [==============================] - 5s 754us/step - loss: 77278341.1494 - mean_squared_error: 77278341.1494\n",
      "Epoch 115/200\n",
      "6692/6692 [==============================] - 5s 748us/step - loss: 77283298.5680 - mean_squared_error: 77283298.5680\n",
      "Epoch 116/200\n",
      "6692/6692 [==============================] - 5s 751us/step - loss: 77251064.9950 - mean_squared_error: 77251064.9950\n",
      "Epoch 117/200\n",
      "6692/6692 [==============================] - 5s 751us/step - loss: 77219619.2455 - mean_squared_error: 77219619.2455\n",
      "Epoch 118/200\n",
      "6692/6692 [==============================] - 5s 748us/step - loss: 77205202.3626 - mean_squared_error: 77205202.3626\n",
      "Epoch 119/200\n",
      "6692/6692 [==============================] - 5s 752us/step - loss: 77160286.4529 - mean_squared_error: 77160286.4529\n",
      "Epoch 120/200\n",
      "6692/6692 [==============================] - 5s 749us/step - loss: 77173498.7382 - mean_squared_error: 77173498.7382\n",
      "Epoch 121/200\n",
      "6692/6692 [==============================] - 5s 751us/step - loss: 77138105.5581 - mean_squared_error: 77138105.5581\n",
      "Epoch 122/200\n",
      "6692/6692 [==============================] - 5s 752us/step - loss: 77114114.4848 - mean_squared_error: 77114114.4848\n",
      "Epoch 123/200\n",
      "6692/6692 [==============================] - 5s 753us/step - loss: 77107655.9127 - mean_squared_error: 77107655.9127\n",
      "Epoch 124/200\n",
      "6692/6692 [==============================] - 5s 752us/step - loss: 77076392.0151 - mean_squared_error: 77076392.0151\n",
      "Epoch 125/200\n",
      "6692/6692 [==============================] - 5s 752us/step - loss: 77040671.1134 - mean_squared_error: 77040671.1134\n",
      "Epoch 126/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6692/6692 [==============================] - 5s 738us/step - loss: 77044547.1100 - mean_squared_error: 77044547.1100\n",
      "Epoch 127/200\n",
      "6692/6692 [==============================] - 5s 733us/step - loss: 77008576.2753 - mean_squared_error: 77008576.2753\n",
      "Epoch 128/200\n",
      "6692/6692 [==============================] - 5s 729us/step - loss: 76990633.6659 - mean_squared_error: 76990633.6659\n",
      "Epoch 129/200\n",
      "6692/6692 [==============================] - 5s 729us/step - loss: 76978634.4077 - mean_squared_error: 76978634.4077\n",
      "Epoch 130/200\n",
      "6692/6692 [==============================] - 5s 729us/step - loss: 76951059.6341 - mean_squared_error: 76951059.6341\n",
      "Epoch 131/200\n",
      "6692/6692 [==============================] - 5s 730us/step - loss: 76918270.4486 - mean_squared_error: 76918270.4486\n",
      "Epoch 132/200\n",
      "6692/6692 [==============================] - 5s 730us/step - loss: 76907570.4159 - mean_squared_error: 76907570.4159\n",
      "Epoch 133/200\n",
      "6692/6692 [==============================] - 5s 729us/step - loss: 76873881.2540 - mean_squared_error: 76873881.2540\n",
      "Epoch 134/200\n",
      "6692/6692 [==============================] - 5s 731us/step - loss: 76857355.0394 - mean_squared_error: 76857355.0394\n",
      "Epoch 135/200\n",
      "6692/6692 [==============================] - 5s 733us/step - loss: 76813110.9538 - mean_squared_error: 76813110.9538\n",
      "Epoch 136/200\n",
      "6692/6692 [==============================] - 5s 732us/step - loss: 76795642.2634 - mean_squared_error: 76795642.2634\n",
      "Epoch 137/200\n",
      "6692/6692 [==============================] - 5s 733us/step - loss: 76773272.2288 - mean_squared_error: 76773272.2288\n",
      "Epoch 138/200\n",
      "6692/6692 [==============================] - 5s 736us/step - loss: 76733399.6305 - mean_squared_error: 76733399.6305\n",
      "Epoch 139/200\n",
      "6692/6692 [==============================] - 5s 730us/step - loss: 76729104.0671 - mean_squared_error: 76729104.0671\n",
      "Epoch 140/200\n",
      "6692/6692 [==============================] - 5s 731us/step - loss: 76703946.2177 - mean_squared_error: 76703946.21770s - loss: 77202564.1239 - mean_squared_error: 77202564.\n",
      "Epoch 141/200\n",
      "6692/6692 [==============================] - 5s 732us/step - loss: 76652351.5120 - mean_squared_error: 76652351.5120\n",
      "Epoch 142/200\n",
      "6692/6692 [==============================] - 5s 731us/step - loss: 76671164.4570 - mean_squared_error: 76671164.4570\n",
      "Epoch 143/200\n",
      "6692/6692 [==============================] - 5s 732us/step - loss: 76652382.4127 - mean_squared_error: 76652382.4127\n",
      "Epoch 144/200\n",
      "6692/6692 [==============================] - 5s 730us/step - loss: 76611815.9529 - mean_squared_error: 76611815.9529\n",
      "Epoch 145/200\n",
      "6692/6692 [==============================] - 5s 731us/step - loss: 76595600.0944 - mean_squared_error: 76595600.0944\n",
      "Epoch 146/200\n",
      "6692/6692 [==============================] - 5s 732us/step - loss: 76580257.6726 - mean_squared_error: 76580257.6726\n",
      "Epoch 147/200\n",
      "6692/6692 [==============================] - 5s 731us/step - loss: 76547700.7127 - mean_squared_error: 76547700.7127\n",
      "Epoch 148/200\n",
      "6692/6692 [==============================] - 5s 734us/step - loss: 76520643.4424 - mean_squared_error: 76520643.4424\n",
      "Epoch 149/200\n",
      "6692/6692 [==============================] - 5s 731us/step - loss: 76511129.4582 - mean_squared_error: 76511129.4582\n",
      "Epoch 150/200\n",
      "6692/6692 [==============================] - 5s 732us/step - loss: 76484686.1895 - mean_squared_error: 76484686.1895\n",
      "Epoch 151/200\n",
      "6692/6692 [==============================] - 5s 749us/step - loss: 76473761.5461 - mean_squared_error: 76473761.5461\n",
      "Epoch 152/200\n",
      "6692/6692 [==============================] - 5s 735us/step - loss: 76441991.7320 - mean_squared_error: 76441991.7320\n",
      "Epoch 153/200\n",
      "6692/6692 [==============================] - 5s 737us/step - loss: 76423479.0781 - mean_squared_error: 76423479.0781\n",
      "Epoch 154/200\n",
      "6692/6692 [==============================] - 5s 737us/step - loss: 76396877.0449 - mean_squared_error: 76396877.0449\n",
      "Epoch 155/200\n",
      "6692/6692 [==============================] - 5s 736us/step - loss: 76366763.3814 - mean_squared_error: 76366763.3814\n",
      "Epoch 156/200\n",
      "6692/6692 [==============================] - 5s 737us/step - loss: 76372175.1886 - mean_squared_error: 76372175.1886\n",
      "Epoch 157/200\n",
      "6692/6692 [==============================] - 5s 746us/step - loss: 76327560.3142 - mean_squared_error: 76327560.3142\n",
      "Epoch 158/200\n",
      "6692/6692 [==============================] - 5s 740us/step - loss: 76312465.2609 - mean_squared_error: 76312465.2609\n",
      "Epoch 159/200\n",
      "6692/6692 [==============================] - 5s 737us/step - loss: 76271803.3431 - mean_squared_error: 76271803.3431\n",
      "Epoch 160/200\n",
      "6692/6692 [==============================] - 5s 739us/step - loss: 76285886.8619 - mean_squared_error: 76285886.8619\n",
      "Epoch 161/200\n",
      "6692/6692 [==============================] - 5s 740us/step - loss: 76257185.5078 - mean_squared_error: 76257185.5078\n",
      "Epoch 162/200\n",
      "6692/6692 [==============================] - 5s 742us/step - loss: 76234260.4041 - mean_squared_error: 76234260.4041\n",
      "Epoch 163/200\n",
      "6692/6692 [==============================] - 5s 747us/step - loss: 76205640.7625 - mean_squared_error: 76205640.7625\n",
      "Epoch 164/200\n",
      "6692/6692 [==============================] - 5s 743us/step - loss: 76168870.2990 - mean_squared_error: 76168870.2990\n",
      "Epoch 165/200\n",
      "6692/6692 [==============================] - 5s 742us/step - loss: 76181014.5298 - mean_squared_error: 76181014.5298\n",
      "Epoch 166/200\n",
      "6692/6692 [==============================] - 5s 741us/step - loss: 76159079.8322 - mean_squared_error: 76159079.8322\n",
      "Epoch 167/200\n",
      "6692/6692 [==============================] - 5s 738us/step - loss: 76132792.6242 - mean_squared_error: 76132792.6242\n",
      "Epoch 168/200\n",
      "6692/6692 [==============================] - 5s 743us/step - loss: 76102690.1106 - mean_squared_error: 76102690.1106\n",
      "Epoch 169/200\n",
      "6692/6692 [==============================] - 5s 740us/step - loss: 76090320.0976 - mean_squared_error: 76090320.0976\n",
      "Epoch 170/200\n",
      "6692/6692 [==============================] - 5s 744us/step - loss: 76065928.4173 - mean_squared_error: 76065928.4173\n",
      "Epoch 171/200\n",
      "6692/6692 [==============================] - 5s 743us/step - loss: 76036484.2916 - mean_squared_error: 76036484.2916\n",
      "Epoch 172/200\n",
      "6692/6692 [==============================] - 5s 773us/step - loss: 76022880.6911 - mean_squared_error: 76022880.6911\n",
      "Epoch 173/200\n",
      "6692/6692 [==============================] - 5s 743us/step - loss: 76014141.7503 - mean_squared_error: 76014141.7503\n",
      "Epoch 174/200\n",
      "6692/6692 [==============================] - 5s 745us/step - loss: 75983562.0524 - mean_squared_error: 75983562.0524\n",
      "Epoch 175/200\n",
      "6692/6692 [==============================] - 5s 759us/step - loss: 75957462.2882 - mean_squared_error: 75957462.2882\n",
      "Epoch 176/200\n",
      "6692/6692 [==============================] - 5s 743us/step - loss: 75900032.0868 - mean_squared_error: 75900032.0868\n",
      "Epoch 177/200\n",
      "6692/6692 [==============================] - 5s 743us/step - loss: 75925495.4028 - mean_squared_error: 75925495.4028\n",
      "Epoch 178/200\n",
      "6692/6692 [==============================] - 5s 744us/step - loss: 75918862.2795 - mean_squared_error: 75918862.2795\n",
      "Epoch 179/200\n",
      "6692/6692 [==============================] - 5s 743us/step - loss: 75897724.6192 - mean_squared_error: 75897724.6192\n",
      "Epoch 180/200\n",
      "6692/6692 [==============================] - 5s 743us/step - loss: 75854858.9146 - mean_squared_error: 75854858.9146\n",
      "Epoch 181/200\n",
      "6692/6692 [==============================] - 5s 744us/step - loss: 75850239.8128 - mean_squared_error: 75850239.8128\n",
      "Epoch 182/200\n",
      "6692/6692 [==============================] - 5s 747us/step - loss: 75827204.4439 - mean_squared_error: 75827204.4439\n",
      "Epoch 183/200\n",
      "6692/6692 [==============================] - 5s 744us/step - loss: 75821474.2789 - mean_squared_error: 75821474.2789\n",
      "Epoch 184/200\n",
      "6692/6692 [==============================] - 5s 749us/step - loss: 75772780.1720 - mean_squared_error: 75772780.1720\n",
      "Epoch 185/200\n",
      "6692/6692 [==============================] - 5s 743us/step - loss: 75776185.6643 - mean_squared_error: 75776185.6643\n",
      "Epoch 186/200\n",
      "6692/6692 [==============================] - 5s 744us/step - loss: 75764826.4865 - mean_squared_error: 75764826.4865\n",
      "Epoch 187/200\n",
      "6692/6692 [==============================] - 5s 751us/step - loss: 75743903.6819 - mean_squared_error: 75743903.6819\n",
      "Epoch 188/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6692/6692 [==============================] - 5s 731us/step - loss: 75708466.2231 - mean_squared_error: 75708466.2231\n",
      "Epoch 189/200\n",
      "6692/6692 [==============================] - 5s 729us/step - loss: 75700178.6228 - mean_squared_error: 75700178.6228\n",
      "Epoch 190/200\n",
      "6692/6692 [==============================] - 5s 728us/step - loss: 75700547.8525 - mean_squared_error: 75700547.8525\n",
      "Epoch 191/200\n",
      "6692/6692 [==============================] - 5s 727us/step - loss: 75671945.4431 - mean_squared_error: 75671945.4431\n",
      "Epoch 192/200\n",
      "6692/6692 [==============================] - 5s 727us/step - loss: 75658939.0502 - mean_squared_error: 75658939.0502\n",
      "Epoch 193/200\n",
      "6692/6692 [==============================] - 5s 729us/step - loss: 75631978.7046 - mean_squared_error: 75631978.7046\n",
      "Epoch 194/200\n",
      "6692/6692 [==============================] - 5s 733us/step - loss: 75614935.9430 - mean_squared_error: 75614935.9430\n",
      "Epoch 195/200\n",
      "6692/6692 [==============================] - 5s 734us/step - loss: 75597404.4231 - mean_squared_error: 75597404.4231\n",
      "Epoch 196/200\n",
      "6692/6692 [==============================] - 5s 729us/step - loss: 75585671.2157 - mean_squared_error: 75585671.2157\n",
      "Epoch 197/200\n",
      "6692/6692 [==============================] - 5s 733us/step - loss: 75565902.7189 - mean_squared_error: 75565902.7189\n",
      "Epoch 198/200\n",
      "6692/6692 [==============================] - 5s 732us/step - loss: 75559493.1312 - mean_squared_error: 75559493.1312\n",
      "Epoch 199/200\n",
      "6692/6692 [==============================] - 5s 748us/step - loss: 75522991.3006 - mean_squared_error: 75522991.3006\n",
      "Epoch 200/200\n",
      "6692/6692 [==============================] - 5s 732us/step - loss: 75508871.4100 - mean_squared_error: 75508871.4100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2731427d898>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model for Y2\n",
    "sque.fit(x_tr2, y_tr2, epochs=200, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2897949967714719"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluat model for Y2\n",
    "sque_pred2 = sque.predict(x_te2)\n",
    "r2_score(y_te2,sque_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "6692/6692 [==============================] - 5s 733us/step - loss: 22360177.8376 - mean_squared_error: 22360177.8376\n",
      "Epoch 2/200\n",
      "6692/6692 [==============================] - 5s 730us/step - loss: 12201960.5894 - mean_squared_error: 12201960.5894\n",
      "Epoch 3/200\n",
      "6692/6692 [==============================] - 5s 733us/step - loss: 8051054.5676 - mean_squared_error: 8051054.5676\n",
      "Epoch 4/200\n",
      "6692/6692 [==============================] - 5s 727us/step - loss: 5697664.3338 - mean_squared_error: 5697664.3338\n",
      "Epoch 5/200\n",
      "6692/6692 [==============================] - 5s 734us/step - loss: 4171613.6033 - mean_squared_error: 4171613.6033\n",
      "Epoch 6/200\n",
      "6692/6692 [==============================] - 5s 732us/step - loss: 3164174.6801 - mean_squared_error: 3164174.6801\n",
      "Epoch 7/200\n",
      "6692/6692 [==============================] - 5s 734us/step - loss: 2445879.3520 - mean_squared_error: 2445879.3520\n",
      "Epoch 8/200\n",
      "6692/6692 [==============================] - 5s 735us/step - loss: 1906039.4264 - mean_squared_error: 1906039.4264\n",
      "Epoch 9/200\n",
      "6692/6692 [==============================] - 5s 734us/step - loss: 1522564.6254 - mean_squared_error: 1522564.6254\n",
      "Epoch 10/200\n",
      "6692/6692 [==============================] - 5s 732us/step - loss: 1254096.0592 - mean_squared_error: 1254096.0592\n",
      "Epoch 11/200\n",
      "6692/6692 [==============================] - 5s 735us/step - loss: 1050632.8355 - mean_squared_error: 1050632.8355\n",
      "Epoch 12/200\n",
      "6692/6692 [==============================] - 5s 738us/step - loss: 878330.1979 - mean_squared_error: 878330.1979\n",
      "Epoch 13/200\n",
      "6692/6692 [==============================] - 5s 737us/step - loss: 720704.6196 - mean_squared_error: 720704.6196\n",
      "Epoch 14/200\n",
      "6692/6692 [==============================] - 5s 738us/step - loss: 588013.3612 - mean_squared_error: 588013.3612\n",
      "Epoch 15/200\n",
      "6692/6692 [==============================] - 5s 736us/step - loss: 486865.0462 - mean_squared_error: 486865.0462\n",
      "Epoch 16/200\n",
      "6692/6692 [==============================] - 5s 734us/step - loss: 420601.2420 - mean_squared_error: 420601.2420\n",
      "Epoch 17/200\n",
      "6692/6692 [==============================] - 5s 737us/step - loss: 363057.1870 - mean_squared_error: 363057.1870\n",
      "Epoch 18/200\n",
      "6692/6692 [==============================] - 5s 735us/step - loss: 311109.2308 - mean_squared_error: 311109.2308\n",
      "Epoch 19/200\n",
      "6692/6692 [==============================] - 5s 736us/step - loss: 266265.3138 - mean_squared_error: 266265.3138\n",
      "Epoch 20/200\n",
      "6692/6692 [==============================] - 5s 737us/step - loss: 229666.6421 - mean_squared_error: 229666.6421\n",
      "Epoch 21/200\n",
      "6692/6692 [==============================] - 5s 742us/step - loss: 202431.0897 - mean_squared_error: 202431.0897\n",
      "Epoch 22/200\n",
      "6692/6692 [==============================] - 5s 741us/step - loss: 178475.9780 - mean_squared_error: 178475.9780\n",
      "Epoch 23/200\n",
      "6692/6692 [==============================] - 5s 746us/step - loss: 156064.7347 - mean_squared_error: 156064.7347\n",
      "Epoch 24/200\n",
      "6692/6692 [==============================] - 5s 751us/step - loss: 137560.7478 - mean_squared_error: 137560.7478\n",
      "Epoch 25/200\n",
      "6692/6692 [==============================] - 5s 745us/step - loss: 122791.7468 - mean_squared_error: 122791.7468\n",
      "Epoch 26/200\n",
      "6692/6692 [==============================] - 5s 744us/step - loss: 109474.5201 - mean_squared_error: 109474.5201\n",
      "Epoch 27/200\n",
      "6692/6692 [==============================] - 5s 746us/step - loss: 98034.9271 - mean_squared_error: 98034.9271\n",
      "Epoch 28/200\n",
      "6692/6692 [==============================] - 5s 744us/step - loss: 87994.1586 - mean_squared_error: 87994.1586\n",
      "Epoch 29/200\n",
      "6692/6692 [==============================] - 5s 746us/step - loss: 78808.6744 - mean_squared_error: 78808.6744\n",
      "Epoch 30/200\n",
      "6692/6692 [==============================] - 5s 745us/step - loss: 70524.1398 - mean_squared_error: 70524.1398\n",
      "Epoch 31/200\n",
      "6692/6692 [==============================] - 5s 744us/step - loss: 63817.4494 - mean_squared_error: 63817.4494\n",
      "Epoch 32/200\n",
      "6692/6692 [==============================] - 5s 754us/step - loss: 56824.2099 - mean_squared_error: 56824.2099\n",
      "Epoch 33/200\n",
      "6692/6692 [==============================] - 5s 746us/step - loss: 49866.3707 - mean_squared_error: 49866.3707\n",
      "Epoch 34/200\n",
      "6692/6692 [==============================] - 5s 749us/step - loss: 43716.5831 - mean_squared_error: 43716.5831\n",
      "Epoch 35/200\n",
      "6692/6692 [==============================] - 5s 749us/step - loss: 38766.6588 - mean_squared_error: 38766.6588\n",
      "Epoch 36/200\n",
      "6692/6692 [==============================] - 5s 755us/step - loss: 34982.4672 - mean_squared_error: 34982.4672\n",
      "Epoch 37/200\n",
      "6692/6692 [==============================] - 5s 750us/step - loss: 30860.7094 - mean_squared_error: 30860.7094\n",
      "Epoch 38/200\n",
      "6692/6692 [==============================] - 5s 751us/step - loss: 27580.5834 - mean_squared_error: 27580.5834\n",
      "Epoch 39/200\n",
      "6692/6692 [==============================] - 5s 753us/step - loss: 24568.2140 - mean_squared_error: 24568.2140\n",
      "Epoch 40/200\n",
      "6692/6692 [==============================] - 5s 751us/step - loss: 21778.0513 - mean_squared_error: 21778.0513\n",
      "Epoch 41/200\n",
      "6692/6692 [==============================] - 5s 748us/step - loss: 18938.0433 - mean_squared_error: 18938.0433\n",
      "Epoch 42/200\n",
      "6692/6692 [==============================] - 5s 749us/step - loss: 16451.0227 - mean_squared_error: 16451.0227\n",
      "Epoch 43/200\n",
      "6692/6692 [==============================] - 5s 749us/step - loss: 14269.8215 - mean_squared_error: 14269.8215\n",
      "Epoch 44/200\n",
      "6692/6692 [==============================] - 5s 750us/step - loss: 12415.2921 - mean_squared_error: 12415.2921\n",
      "Epoch 45/200\n",
      "6692/6692 [==============================] - 5s 752us/step - loss: 10795.4589 - mean_squared_error: 10795.4589\n",
      "Epoch 46/200\n",
      "6692/6692 [==============================] - 5s 752us/step - loss: 9192.1479 - mean_squared_error: 9192.1479\n",
      "Epoch 47/200\n",
      "6692/6692 [==============================] - 5s 754us/step - loss: 7828.2483 - mean_squared_error: 7828.2483\n",
      "Epoch 48/200\n",
      "6692/6692 [==============================] - 5s 764us/step - loss: 6523.7619 - mean_squared_error: 6523.7619\n",
      "Epoch 49/200\n",
      "6692/6692 [==============================] - 5s 757us/step - loss: 5369.3351 - mean_squared_error: 5369.3351\n",
      "Epoch 50/200\n",
      "6692/6692 [==============================] - 5s 753us/step - loss: 4386.9676 - mean_squared_error: 4386.9676\n",
      "Epoch 51/200\n",
      "6692/6692 [==============================] - 5s 753us/step - loss: 3673.6590 - mean_squared_error: 3673.6590\n",
      "Epoch 52/200\n",
      "6692/6692 [==============================] - 5s 757us/step - loss: 2906.7232 - mean_squared_error: 2906.7232\n",
      "Epoch 53/200\n",
      "6692/6692 [==============================] - 5s 752us/step - loss: 2266.7248 - mean_squared_error: 2266.7248\n",
      "Epoch 54/200\n",
      "6692/6692 [==============================] - 5s 756us/step - loss: 1742.5606 - mean_squared_error: 1742.5606\n",
      "Epoch 55/200\n",
      "6692/6692 [==============================] - 5s 752us/step - loss: 1308.4555 - mean_squared_error: 1308.4555\n",
      "Epoch 56/200\n",
      "6692/6692 [==============================] - 5s 752us/step - loss: 1048.6432 - mean_squared_error: 1048.6432\n",
      "Epoch 57/200\n",
      "6692/6692 [==============================] - 5s 755us/step - loss: 849.0030 - mean_squared_error: 849.0030\n",
      "Epoch 58/200\n",
      "6692/6692 [==============================] - 5s 754us/step - loss: 693.7223 - mean_squared_error: 693.7223\n",
      "Epoch 59/200\n",
      "6692/6692 [==============================] - 5s 754us/step - loss: 548.6961 - mean_squared_error: 548.6961\n",
      "Epoch 60/200\n",
      "6692/6692 [==============================] - 5s 762us/step - loss: 438.6006 - mean_squared_error: 438.6006\n",
      "Epoch 61/200\n",
      "6692/6692 [==============================] - 5s 756us/step - loss: 341.0820 - mean_squared_error: 341.0820\n",
      "Epoch 62/200\n",
      "6692/6692 [==============================] - 5s 758us/step - loss: 258.2075 - mean_squared_error: 258.2075\n",
      "Epoch 63/200\n",
      "6692/6692 [==============================] - 5s 755us/step - loss: 199.7904 - mean_squared_error: 199.7904\n",
      "Epoch 64/200\n",
      "6692/6692 [==============================] - 5s 755us/step - loss: 155.2056 - mean_squared_error: 155.2056\n",
      "Epoch 65/200\n",
      "6692/6692 [==============================] - 5s 756us/step - loss: 115.3553 - mean_squared_error: 115.3553\n",
      "Epoch 66/200\n",
      "6692/6692 [==============================] - 5s 756us/step - loss: 83.5325 - mean_squared_error: 83.5325\n",
      "Epoch 67/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6692/6692 [==============================] - 5s 727us/step - loss: 60.7845 - mean_squared_error: 60.7845\n",
      "Epoch 68/200\n",
      "6692/6692 [==============================] - 5s 727us/step - loss: 38.4578 - mean_squared_error: 38.4578\n",
      "Epoch 69/200\n",
      "6692/6692 [==============================] - 5s 725us/step - loss: 23.5754 - mean_squared_error: 23.5754\n",
      "Epoch 70/200\n",
      "6692/6692 [==============================] - 5s 728us/step - loss: 11.9817 - mean_squared_error: 11.9817\n",
      "Epoch 71/200\n",
      "6692/6692 [==============================] - 5s 735us/step - loss: 6.1569 - mean_squared_error: 6.1569\n",
      "Epoch 72/200\n",
      "6692/6692 [==============================] - 5s 740us/step - loss: 4.0854 - mean_squared_error: 4.0854\n",
      "Epoch 73/200\n",
      "6692/6692 [==============================] - 5s 731us/step - loss: 3.5843 - mean_squared_error: 3.5843\n",
      "Epoch 74/200\n",
      "6692/6692 [==============================] - 5s 732us/step - loss: 3.2502 - mean_squared_error: 3.2502\n",
      "Epoch 75/200\n",
      "6692/6692 [==============================] - 5s 734us/step - loss: 3.1591 - mean_squared_error: 3.1591\n",
      "Epoch 76/200\n",
      "6692/6692 [==============================] - 5s 735us/step - loss: 3.1665 - mean_squared_error: 3.1665\n",
      "Epoch 77/200\n",
      "6692/6692 [==============================] - 5s 733us/step - loss: 3.1720 - mean_squared_error: 3.1720\n",
      "Epoch 78/200\n",
      "6692/6692 [==============================] - 5s 733us/step - loss: 3.2095 - mean_squared_error: 3.2095\n",
      "Epoch 79/200\n",
      "6692/6692 [==============================] - 5s 733us/step - loss: 3.1745 - mean_squared_error: 3.1745\n",
      "Epoch 80/200\n",
      "6692/6692 [==============================] - 5s 733us/step - loss: 3.1692 - mean_squared_error: 3.1692\n",
      "Epoch 81/200\n",
      "6692/6692 [==============================] - 5s 731us/step - loss: 3.1716 - mean_squared_error: 3.1716\n",
      "Epoch 82/200\n",
      "6692/6692 [==============================] - 5s 734us/step - loss: 3.1731 - mean_squared_error: 3.1731\n",
      "Epoch 83/200\n",
      "6692/6692 [==============================] - 5s 731us/step - loss: 3.1696 - mean_squared_error: 3.1696\n",
      "Epoch 84/200\n",
      "6692/6692 [==============================] - 5s 742us/step - loss: 3.1691 - mean_squared_error: 3.1691\n",
      "Epoch 85/200\n",
      "6692/6692 [==============================] - 5s 736us/step - loss: 3.1684 - mean_squared_error: 3.1684\n",
      "Epoch 86/200\n",
      "6692/6692 [==============================] - 5s 735us/step - loss: 3.1695 - mean_squared_error: 3.1695\n",
      "Epoch 87/200\n",
      "6692/6692 [==============================] - 5s 734us/step - loss: 3.1686 - mean_squared_error: 3.1686\n",
      "Epoch 88/200\n",
      "6692/6692 [==============================] - 5s 736us/step - loss: 3.1622 - mean_squared_error: 3.1622\n",
      "Epoch 89/200\n",
      "6692/6692 [==============================] - 5s 740us/step - loss: 3.1657 - mean_squared_error: 3.1657\n",
      "Epoch 90/200\n",
      "6692/6692 [==============================] - 5s 738us/step - loss: 3.1673 - mean_squared_error: 3.1673\n",
      "Epoch 91/200\n",
      "6692/6692 [==============================] - 5s 739us/step - loss: 3.1653 - mean_squared_error: 3.1653\n",
      "Epoch 92/200\n",
      "6692/6692 [==============================] - 5s 754us/step - loss: 3.1637 - mean_squared_error: 3.1637\n",
      "Epoch 93/200\n",
      "6692/6692 [==============================] - 5s 740us/step - loss: 3.1710 - mean_squared_error: 3.1710\n",
      "Epoch 94/200\n",
      "6692/6692 [==============================] - 5s 745us/step - loss: 3.1671 - mean_squared_error: 3.1671\n",
      "Epoch 95/200\n",
      "6692/6692 [==============================] - 5s 744us/step - loss: 3.1653 - mean_squared_error: 3.1653\n",
      "Epoch 96/200\n",
      "6692/6692 [==============================] - 5s 757us/step - loss: 3.1669 - mean_squared_error: 3.1669\n",
      "Epoch 97/200\n",
      "6692/6692 [==============================] - 5s 745us/step - loss: 3.1658 - mean_squared_error: 3.1658\n",
      "Epoch 98/200\n",
      "6692/6692 [==============================] - 5s 743us/step - loss: 3.1706 - mean_squared_error: 3.1706\n",
      "Epoch 99/200\n",
      "6692/6692 [==============================] - 5s 742us/step - loss: 3.1698 - mean_squared_error: 3.1698\n",
      "Epoch 100/200\n",
      "6692/6692 [==============================] - 5s 742us/step - loss: 3.1720 - mean_squared_error: 3.1720\n",
      "Epoch 101/200\n",
      "6692/6692 [==============================] - 5s 743us/step - loss: 3.1703 - mean_squared_error: 3.1703\n",
      "Epoch 102/200\n",
      "6692/6692 [==============================] - 5s 744us/step - loss: 3.1650 - mean_squared_error: 3.1650\n",
      "Epoch 103/200\n",
      "6692/6692 [==============================] - 5s 747us/step - loss: 3.1690 - mean_squared_error: 3.1690\n",
      "Epoch 104/200\n",
      "6692/6692 [==============================] - 5s 745us/step - loss: 3.1698 - mean_squared_error: 3.1698\n",
      "Epoch 105/200\n",
      "6692/6692 [==============================] - 5s 745us/step - loss: 3.1718 - mean_squared_error: 3.1718\n",
      "Epoch 106/200\n",
      "6692/6692 [==============================] - 5s 745us/step - loss: 3.1616 - mean_squared_error: 3.1616\n",
      "Epoch 107/200\n",
      "6692/6692 [==============================] - 5s 745us/step - loss: 3.1696 - mean_squared_error: 3.1696\n",
      "Epoch 108/200\n",
      "6692/6692 [==============================] - 5s 750us/step - loss: 3.1658 - mean_squared_error: 3.1658\n",
      "Epoch 109/200\n",
      "6692/6692 [==============================] - 5s 750us/step - loss: 3.1739 - mean_squared_error: 3.1739\n",
      "Epoch 110/200\n",
      "6692/6692 [==============================] - 5s 748us/step - loss: 3.1743 - mean_squared_error: 3.1743\n",
      "Epoch 111/200\n",
      "6692/6692 [==============================] - 5s 748us/step - loss: 3.1640 - mean_squared_error: 3.1640\n",
      "Epoch 112/200\n",
      "6692/6692 [==============================] - 5s 747us/step - loss: 3.1667 - mean_squared_error: 3.1667\n",
      "Epoch 113/200\n",
      "6692/6692 [==============================] - 5s 747us/step - loss: 3.1682 - mean_squared_error: 3.1682\n",
      "Epoch 114/200\n",
      "6692/6692 [==============================] - 5s 748us/step - loss: 3.1719 - mean_squared_error: 3.1719\n",
      "Epoch 115/200\n",
      "6692/6692 [==============================] - 5s 747us/step - loss: 3.1745 - mean_squared_error: 3.1745\n",
      "Epoch 116/200\n",
      "6692/6692 [==============================] - 5s 745us/step - loss: 3.1788 - mean_squared_error: 3.1788\n",
      "Epoch 117/200\n",
      "6692/6692 [==============================] - 5s 748us/step - loss: 3.1697 - mean_squared_error: 3.1697\n",
      "Epoch 118/200\n",
      "6692/6692 [==============================] - 5s 744us/step - loss: 3.1651 - mean_squared_error: 3.1651\n",
      "Epoch 119/200\n",
      "6692/6692 [==============================] - 5s 747us/step - loss: 3.1700 - mean_squared_error: 3.1700\n",
      "Epoch 120/200\n",
      "6692/6692 [==============================] - 5s 759us/step - loss: 3.1734 - mean_squared_error: 3.1734\n",
      "Epoch 121/200\n",
      "6692/6692 [==============================] - 5s 748us/step - loss: 3.1681 - mean_squared_error: 3.1681\n",
      "Epoch 122/200\n",
      "6692/6692 [==============================] - 5s 747us/step - loss: 3.1690 - mean_squared_error: 3.1690\n",
      "Epoch 123/200\n",
      "6692/6692 [==============================] - 5s 752us/step - loss: 3.1722 - mean_squared_error: 3.1722\n",
      "Epoch 124/200\n",
      "6692/6692 [==============================] - 5s 749us/step - loss: 3.1656 - mean_squared_error: 3.1656\n",
      "Epoch 125/200\n",
      "6692/6692 [==============================] - 5s 748us/step - loss: 3.1701 - mean_squared_error: 3.1701\n",
      "Epoch 126/200\n",
      "6692/6692 [==============================] - 5s 750us/step - loss: 3.1655 - mean_squared_error: 3.1655\n",
      "Epoch 127/200\n",
      "6692/6692 [==============================] - 5s 756us/step - loss: 3.1695 - mean_squared_error: 3.1695\n",
      "Epoch 128/200\n",
      "6692/6692 [==============================] - 5s 750us/step - loss: 3.1721 - mean_squared_error: 3.1721\n",
      "Epoch 129/200\n",
      "6692/6692 [==============================] - 5s 751us/step - loss: 3.1671 - mean_squared_error: 3.1671\n",
      "Epoch 130/200\n",
      "6692/6692 [==============================] - 5s 749us/step - loss: 3.1670 - mean_squared_error: 3.1670\n",
      "Epoch 131/200\n",
      "6692/6692 [==============================] - 5s 750us/step - loss: 3.1623 - mean_squared_error: 3.1623\n",
      "Epoch 132/200\n",
      "6692/6692 [==============================] - 5s 755us/step - loss: 3.1702 - mean_squared_error: 3.1702\n",
      "Epoch 133/200\n",
      "6692/6692 [==============================] - 5s 752us/step - loss: 3.1699 - mean_squared_error: 3.1699\n",
      "Epoch 134/200\n",
      "6692/6692 [==============================] - 5s 751us/step - loss: 3.1633 - mean_squared_error: 3.1633\n",
      "Epoch 135/200\n",
      "6692/6692 [==============================] - 5s 750us/step - loss: 3.1741 - mean_squared_error: 3.1741\n",
      "Epoch 136/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6692/6692 [==============================] - 5s 751us/step - loss: 3.1648 - mean_squared_error: 3.16480s - loss: 3.1465 - mean_squar\n",
      "Epoch 137/200\n",
      "6692/6692 [==============================] - 5s 725us/step - loss: 3.1709 - mean_squared_error: 3.1709\n",
      "Epoch 138/200\n",
      "6692/6692 [==============================] - 5s 728us/step - loss: 3.1690 - mean_squared_error: 3.1690\n",
      "Epoch 139/200\n",
      "6692/6692 [==============================] - 5s 728us/step - loss: 3.1703 - mean_squared_error: 3.1703\n",
      "Epoch 140/200\n",
      "6692/6692 [==============================] - 5s 726us/step - loss: 3.1691 - mean_squared_error: 3.1691\n",
      "Epoch 141/200\n",
      "6692/6692 [==============================] - 5s 725us/step - loss: 3.1705 - mean_squared_error: 3.1705\n",
      "Epoch 142/200\n",
      "6692/6692 [==============================] - 5s 727us/step - loss: 3.1677 - mean_squared_error: 3.1677\n",
      "Epoch 143/200\n",
      "6692/6692 [==============================] - 5s 727us/step - loss: 3.1693 - mean_squared_error: 3.1693\n",
      "Epoch 144/200\n",
      "6692/6692 [==============================] - 5s 742us/step - loss: 3.1698 - mean_squared_error: 3.1698\n",
      "Epoch 145/200\n",
      "6692/6692 [==============================] - 5s 730us/step - loss: 3.1741 - mean_squared_error: 3.1741\n",
      "Epoch 146/200\n",
      "6692/6692 [==============================] - 5s 728us/step - loss: 3.1669 - mean_squared_error: 3.1669\n",
      "Epoch 147/200\n",
      "6692/6692 [==============================] - 5s 731us/step - loss: 3.1721 - mean_squared_error: 3.1721\n",
      "Epoch 148/200\n",
      "6692/6692 [==============================] - 5s 729us/step - loss: 3.1733 - mean_squared_error: 3.1733\n",
      "Epoch 149/200\n",
      "6692/6692 [==============================] - 5s 732us/step - loss: 3.1716 - mean_squared_error: 3.1716\n",
      "Epoch 150/200\n",
      "6692/6692 [==============================] - 5s 730us/step - loss: 3.1689 - mean_squared_error: 3.1689\n",
      "Epoch 151/200\n",
      "6692/6692 [==============================] - 5s 730us/step - loss: 3.1677 - mean_squared_error: 3.1677\n",
      "Epoch 152/200\n",
      "6692/6692 [==============================] - 5s 733us/step - loss: 3.1692 - mean_squared_error: 3.1692\n",
      "Epoch 153/200\n",
      "6692/6692 [==============================] - 5s 743us/step - loss: 3.1686 - mean_squared_error: 3.1686\n",
      "Epoch 154/200\n",
      "6692/6692 [==============================] - 5s 733us/step - loss: 3.1698 - mean_squared_error: 3.1698\n",
      "Epoch 155/200\n",
      "6692/6692 [==============================] - 5s 732us/step - loss: 3.1729 - mean_squared_error: 3.1729\n",
      "Epoch 156/200\n",
      "6692/6692 [==============================] - 5s 756us/step - loss: 3.1681 - mean_squared_error: 3.1681\n",
      "Epoch 157/200\n",
      "6692/6692 [==============================] - 5s 739us/step - loss: 3.1621 - mean_squared_error: 3.1621\n",
      "Epoch 158/200\n",
      "6692/6692 [==============================] - 5s 735us/step - loss: 3.1707 - mean_squared_error: 3.1707\n",
      "Epoch 159/200\n",
      "6692/6692 [==============================] - 5s 734us/step - loss: 3.1693 - mean_squared_error: 3.1693\n",
      "Epoch 160/200\n",
      "6692/6692 [==============================] - 5s 736us/step - loss: 3.1661 - mean_squared_error: 3.1661\n",
      "Epoch 161/200\n",
      "6692/6692 [==============================] - 5s 735us/step - loss: 3.1648 - mean_squared_error: 3.1648\n",
      "Epoch 162/200\n",
      "6692/6692 [==============================] - 5s 733us/step - loss: 3.1720 - mean_squared_error: 3.1720\n",
      "Epoch 163/200\n",
      "6692/6692 [==============================] - 5s 734us/step - loss: 3.1697 - mean_squared_error: 3.1697\n",
      "Epoch 164/200\n",
      "6692/6692 [==============================] - 5s 739us/step - loss: 3.1714 - mean_squared_error: 3.1714\n",
      "Epoch 165/200\n",
      "6692/6692 [==============================] - 5s 734us/step - loss: 3.1702 - mean_squared_error: 3.1702\n",
      "Epoch 166/200\n",
      "6692/6692 [==============================] - 5s 739us/step - loss: 3.1782 - mean_squared_error: 3.1782\n",
      "Epoch 167/200\n",
      "6692/6692 [==============================] - 5s 737us/step - loss: 3.1704 - mean_squared_error: 3.1704\n",
      "Epoch 168/200\n",
      "6692/6692 [==============================] - 5s 749us/step - loss: 3.1669 - mean_squared_error: 3.1669\n",
      "Epoch 169/200\n",
      "6692/6692 [==============================] - 5s 744us/step - loss: 3.1632 - mean_squared_error: 3.1632\n",
      "Epoch 170/200\n",
      "6692/6692 [==============================] - 5s 740us/step - loss: 3.1683 - mean_squared_error: 3.1683\n",
      "Epoch 171/200\n",
      "6692/6692 [==============================] - 5s 738us/step - loss: 3.1689 - mean_squared_error: 3.1689\n",
      "Epoch 172/200\n",
      "6692/6692 [==============================] - 5s 740us/step - loss: 3.1640 - mean_squared_error: 3.1640\n",
      "Epoch 173/200\n",
      "6692/6692 [==============================] - 5s 739us/step - loss: 3.1627 - mean_squared_error: 3.1627\n",
      "Epoch 174/200\n",
      "6692/6692 [==============================] - 5s 738us/step - loss: 3.1681 - mean_squared_error: 3.1681\n",
      "Epoch 175/200\n",
      "6692/6692 [==============================] - 5s 739us/step - loss: 3.1655 - mean_squared_error: 3.1655\n",
      "Epoch 176/200\n",
      "6692/6692 [==============================] - 5s 740us/step - loss: 3.1666 - mean_squared_error: 3.1666\n",
      "Epoch 177/200\n",
      "6692/6692 [==============================] - 5s 741us/step - loss: 3.1655 - mean_squared_error: 3.1655\n",
      "Epoch 178/200\n",
      "6692/6692 [==============================] - 5s 741us/step - loss: 3.1761 - mean_squared_error: 3.1761\n",
      "Epoch 179/200\n",
      "6692/6692 [==============================] - 5s 740us/step - loss: 3.1710 - mean_squared_error: 3.1710\n",
      "Epoch 180/200\n",
      "6692/6692 [==============================] - 5s 741us/step - loss: 3.1660 - mean_squared_error: 3.1660\n",
      "Epoch 181/200\n",
      "6692/6692 [==============================] - 5s 746us/step - loss: 3.1686 - mean_squared_error: 3.1686\n",
      "Epoch 182/200\n",
      "6692/6692 [==============================] - 5s 743us/step - loss: 3.1642 - mean_squared_error: 3.1642\n",
      "Epoch 183/200\n",
      "6692/6692 [==============================] - 5s 741us/step - loss: 3.1695 - mean_squared_error: 3.1695\n",
      "Epoch 184/200\n",
      "6692/6692 [==============================] - 5s 742us/step - loss: 3.1726 - mean_squared_error: 3.1726\n",
      "Epoch 185/200\n",
      "6692/6692 [==============================] - 5s 742us/step - loss: 3.1648 - mean_squared_error: 3.1648\n",
      "Epoch 186/200\n",
      "6692/6692 [==============================] - 5s 743us/step - loss: 3.1700 - mean_squared_error: 3.1700\n",
      "Epoch 187/200\n",
      "6692/6692 [==============================] - 5s 740us/step - loss: 3.1711 - mean_squared_error: 3.1711\n",
      "Epoch 188/200\n",
      "6692/6692 [==============================] - 5s 743us/step - loss: 3.1689 - mean_squared_error: 3.1689\n",
      "Epoch 189/200\n",
      "6692/6692 [==============================] - 5s 742us/step - loss: 3.1707 - mean_squared_error: 3.1707\n",
      "Epoch 190/200\n",
      "6692/6692 [==============================] - 5s 741us/step - loss: 3.1718 - mean_squared_error: 3.1718\n",
      "Epoch 191/200\n",
      "6692/6692 [==============================] - 5s 744us/step - loss: 3.1705 - mean_squared_error: 3.1705\n",
      "Epoch 192/200\n",
      "6692/6692 [==============================] - 5s 746us/step - loss: 3.1694 - mean_squared_error: 3.1694\n",
      "Epoch 193/200\n",
      "6692/6692 [==============================] - 5s 748us/step - loss: 3.1723 - mean_squared_error: 3.1723\n",
      "Epoch 194/200\n",
      "6692/6692 [==============================] - 5s 742us/step - loss: 3.1695 - mean_squared_error: 3.1695\n",
      "Epoch 195/200\n",
      "6692/6692 [==============================] - 5s 743us/step - loss: 3.1690 - mean_squared_error: 3.1690\n",
      "Epoch 196/200\n",
      "6692/6692 [==============================] - 5s 740us/step - loss: 3.1708 - mean_squared_error: 3.1708\n",
      "Epoch 197/200\n",
      "6692/6692 [==============================] - 5s 743us/step - loss: 3.1690 - mean_squared_error: 3.1690\n",
      "Epoch 198/200\n",
      "6692/6692 [==============================] - 5s 742us/step - loss: 3.1741 - mean_squared_error: 3.1741\n",
      "Epoch 199/200\n",
      "6692/6692 [==============================] - 5s 744us/step - loss: 3.1646 - mean_squared_error: 3.1646\n",
      "Epoch 200/200\n",
      "6692/6692 [==============================] - 5s 743us/step - loss: 3.1723 - mean_squared_error: 3.1723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x273011eb6a0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model for Y3\n",
    "sque.fit(x_tr3, y_tr3, epochs=200, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-127519.72522833198"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluat model for Y3\n",
    "sque_pred3 = sque.predict(x_te3)\n",
    "r2_score(y_te3,sque_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
